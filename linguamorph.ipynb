{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff53df9c",
   "metadata": {},
   "source": [
    "# LINGUAMORPH\n",
    "\n",
    "The software in this notebook is intended to take in text and output variations in sound and stress.\n",
    "\n",
    "Potential applications include:\n",
    "\n",
    "  - homophone phrases (variations on a phrase that sound the same or similar)\n",
    "  - extreme alliteration\n",
    "  - spoonerism-style scrambles\n",
    "  - homophone anagrams\n",
    "  - homophone loops\n",
    "  - shrinking and expanding text\n",
    "  - two different stories that sound the same\n",
    "  - text that morphs to text with meaningful intermediates\n",
    "  - stress-rhythm-seeded text\n",
    "  - faux/foe translations\n",
    "  - rhyming/rapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc51f1a6",
   "metadata": {},
   "source": [
    "## Phonemes and Carnegie Mellon Pronouncing Dictionary\n",
    "\n",
    "(See https://github.com/cmusphinx/cmudict/tree/4c6a365cea2c34340ffc218d5af7a38920fa7e37)\n",
    "\n",
    "From https://www.nltk.org/_modules/nltk/corpus/reader/cmudict.html:\n",
    "\n",
    "The Carnegie Mellon Pronouncing Dictionary [cmudict.0.6]\n",
    "Copyright 1998 Carnegie Mellon University\n",
    "\n",
    "File Format: Each line consists of an uppercased word, a counter\n",
    "(for alternative pronunciations), and a transcription.  Vowels are\n",
    "marked for stress (1=primary, 2=secondary, 0=no stress).  E.g.:\n",
    "NATURAL 1 N AE1 CH ER0 AH0 L\n",
    "\n",
    "The dictionary contains 127069 entries.  Of these, 119400 words are assigned\n",
    "a unique pronunciation, 6830 words have two pronunciations, and 839 words have\n",
    "three or more pronunciations.  Many of these are fast-speech variants.\n",
    "\n",
    "Phonemes: There are 39 phonemes (more at https://en.wikipedia.org/wiki/ARPABET):\n",
    "\n",
    "    Phoneme Example Translation    Phoneme Example Translation\n",
    "    ------- ------- -----------    ------- ------- -----------\n",
    "    AA      odd     AA D           AE      at      AE T\n",
    "    AH      hut     HH AH T        AO      ought   AO T\n",
    "    AW      cow     K AW           AY      hide    HH AY D\n",
    "    B       be      B IY           CH      cheese  CH IY Z\n",
    "    D       dee     D IY           DH      thee    DH IY\n",
    "    EH      Ed      EH D           ER      hurt    HH ER T  -- CHANGE:    ER      hurt    HH ER R T\n",
    "    EY      ate     EY T           F       fee     F IY\n",
    "    G       green   G R IY N       HH      he      HH IY\n",
    "    IH      it      IH T           IY      eat     IY T\n",
    "    JH      gee     JH IY          K       key     K IY\n",
    "    L       lee     L IY           M       me      M IY\n",
    "    N       knee    N IY           NG      ping    P IH NG\n",
    "    OW      oat     OW T           OY      toy     T OY\n",
    "    P       pee     P IY           R       read    R IY D\n",
    "    S       sea     S IY           SH      she     SH IY\n",
    "    T       tea     T IY           TH      theta   TH EY T AH\n",
    "    UH      hood    HH UH D        UW      two     T UW\n",
    "    V       vee     V IY           W       we      W IY\n",
    "    Y       yield   Y IY L D       Z       zee     Z IY\n",
    "    ZH      seizure S IY ZH ER\n",
    "    \n",
    "From https://www.pythonstudio.us/language-processing/a-pronouncing-dictionary.html:\n",
    "\n",
    "For each word, this lexicon provides a list of phonetic codes—distinct labels for each contrastive sound—known as phones. Observe that fire has two pronunciations (in U.S. English): the one-syllable F AY1 R, and the two-syllable F AY1 ER0. The symbols in the CMU Pronouncing Dictionary are from the Arpabet, described in more detail at http://en.wikipedia.org/wiki/Arpabet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4571cffa",
   "metadata": {},
   "source": [
    "## Code to check grammar\n",
    "- ChatGPT API (best, but slow)\n",
    "- Caribe (better than LanguageTool in my tests): https://pypi.org/project/Caribe/\n",
    "- LanguageTool (very basic checks): https://github.com/jxmorris12/language_tool_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea0b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "\n",
    "# Import the grammar checker:\n",
    "grammar_tool = \"caribe\"\n",
    "#grammar_tool = \"language_tool\"\n",
    "#grammar_tool = \"chatgpt4\"\n",
    "#grammar_tool = \"chatgpt3\"\n",
    "# Some tools are too permissive as grammar checkers, so optionally \n",
    "# check a sentence's grammar again with a second tool if it passes the first test:\n",
    "do_check_grammar_again = True  \n",
    "grammar_tool2 = \"chatgpt4\"\n",
    "\n",
    "if grammar_tool == \"chatgpt4\" or (do_check_grammar_again and grammar_tool2==\"chatgpt4\"):\n",
    "    import os\n",
    "    import openai\n",
    "    openai.api_key = os.getenv(\"OPENAI4_API_KEY\")\n",
    "    chatgpt_model = \"gpt-4\"\n",
    "if grammar_tool == \"chatgpt3\" or (do_check_grammar_again and grammar_tool2==\"chatgpt3\"):\n",
    "    import os\n",
    "    import openai\n",
    "    openai.api_key = os.getenv(\"OPENAI3_API_KEY\")\n",
    "    chatgpt_model = \"gpt-3.5-turbo\" #\"text-davinci-003\"\n",
    "if grammar_tool == \"caribe\" or (do_check_grammar_again and grammar_tool2==\"caribe\"):\n",
    "    import Caribe as cb    \n",
    "if grammar_tool == \"language_tool\" or (do_check_grammar_again and grammar_tool2==\"language_tool\"):\n",
    "    import language_tool_python\n",
    "    language_tool_object = language_tool_python.LanguageTool('en-US')\n",
    "    ignore_rules = ['UPPERCASE_SENTENCE_START','I_LOWERCASE'] #'EN_COMPOUNDS','CD_NN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ce991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chatgpt_response(prompt, model):\n",
    "    completion = openai.ChatCompletion.create(model=model, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    response = completion.choices[0].message.content\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def check_grammar(input_sentence, grammar_tool=\"caribe\", cap_and_punc=True, verbose=False):\n",
    "    '''\n",
    "    Check whether an input sentence has correct grammar according to a given grammar tool.\n",
    "    \n",
    "    >>> input_sentence = \"Language continues to evolve.\"\n",
    "    >>> check_grammar(input_sentence, grammar_tool=\"caribe\", cap_and_punc=True, verbose=False)\n",
    "    True    \n",
    "    '''\n",
    "    is_correct = False\n",
    "\n",
    "    # Capitalize the first word and add a period if no punctuation at the end of the input text string.\n",
    "    if cap_and_punc:\n",
    "        input_sentence = input_sentence.capitalize()\n",
    "        if input_sentence[-1] not in string.punctuation: \n",
    "            input_sentence += '.'\n",
    "        \n",
    "\n",
    "    # Check grammar with ChatGPT\n",
    "    if grammar_tool == \"chatgpt4\" or grammar_tool == \"chatgpt3\":\n",
    "        prompt = \"Return just the number 1 if the following sentence is grammatically correct, or just the number 0 if it is not: '{0}'\".format(input_sentence)\n",
    "        response = generate_chatgpt_response(prompt=prompt, model=chatgpt_model)\n",
    "        if response == '1':\n",
    "            is_correct = True\n",
    "            if verbose:\n",
    "                print(\"CORRECT (ChatGPT): {0}\".format(input_sentence))\n",
    "        elif verbose:\n",
    "            print(\"      X (ChatGPT): {0}\".format(input_sentence))\n",
    "\n",
    "    # Check grammar with Caribe\n",
    "    elif grammar_tool == \"caribe\":\n",
    "        output_sentence = cb.caribe_corrector(input_sentence)\n",
    "        if cap_and_punc:\n",
    "            output_sentence = output_sentence.capitalize()\n",
    "            if output_sentence[-1] not in string.punctuation: \n",
    "                output_sentence += '.'\n",
    "        if output_sentence == input_sentence:\n",
    "            is_correct = True\n",
    "            if verbose:\n",
    "                print(\"CORRECT (Caribe): {0}\".format(input_sentence))\n",
    "        elif verbose:\n",
    "            print(\"      X (Caribe): {0}\".format(input_sentence))\n",
    "\n",
    "    # Check grammar with LanguageTool\n",
    "    elif grammar_tool == \"language_tool\":\n",
    "        is_correct = True\n",
    "        for rule in language_tool_object.check(input_sentence):\n",
    "            if rule.ruleId not in ignore_rules:\n",
    "                is_correct = False\n",
    "                if verbose:\n",
    "                    print(rule, end='\\n\\n')\n",
    "        if is_correct:\n",
    "            if verbose:\n",
    "                print(\"CORRECT (LanguageTool): {0}\".format(input_sentence))\n",
    "            elif verbose:\n",
    "                print(\"      X (LanguageTool): {0}\".format(input_sentence))\n",
    "\n",
    "    return is_correct\n",
    "\n",
    "\n",
    "def check_grammar_twice(list_of_sentences, grammar_tool1=\"caribe\", grammar_tool2=\"chatgpt4\", \n",
    "                        cap_and_punc=True, do_check_grammar_again=False, verbose=False):\n",
    "    '''\n",
    "    Check whether an input sentence has correct grammar according to two grammar tools.\n",
    "    \n",
    "    >>> list_of_sentences = ['language continue toys evolve', 'languages continue to evolve']\n",
    "    >>> check_grammar_twice(list_of_sentences, \"caribe\", \"chatgpt4\", True, True, True)\n",
    "          X (Caribe): Language continue toys evolve.\n",
    "    CORRECT (Caribe): Languages continue to evolve.\n",
    "    CORRECT (ChatGPT): Languages continue to evolve.\n",
    "    ['languages continue to evolve']    \n",
    "    '''\n",
    "    is_correct = False\n",
    "\n",
    "    new_list = []\n",
    "    for sentence in list_of_sentences:\n",
    "        #if verbose:\n",
    "        #    print(\"     Input sentence: {0}\".format(sentence))\n",
    "        is_correct = check_grammar(sentence, grammar_tool1, cap_and_punc, verbose)\n",
    "        if is_correct and do_check_grammar_again:\n",
    "            is_correct = check_grammar(sentence, grammar_tool2, cap_and_punc, verbose)\n",
    "        if is_correct:\n",
    "            new_list.append(sentence)\n",
    "\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84caa8",
   "metadata": {},
   "source": [
    "## Code to prepare CMU words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c6b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: vowel 'ER' converted to vowel 'ER' and consonant 'R'\n",
    "phoneme_list = ['AA','AH','AW','B','D','EH','EY','G','IH','JH','L','N','OW','P','S','T','UH','V','Y','ZH',\n",
    "                'AE','AO','AY','CH','DH','ER','F','HH','IY','K','M','NG','OY','R','SH','TH','UW','W','Z']\n",
    "#vowel_list = ['AA','AH','AW','EH','EY','IH','OW','UH','AE','AO','AY','IY','OY','UW','ER']\n",
    "single_consonants = ['B','D','G','JH','L','N','P','S','T','V','Y','ZH','CH',\n",
    "                     'DH','F','HH','K','M','NG','R','SH','TH','W','Z']\n",
    "multiple_consonants = []\n",
    "for c1 in single_consonants:\n",
    "    for c2 in single_consonants:\n",
    "        if c2 != c1:\n",
    "            multiple_consonants.append(c1 + '+' + c2)\n",
    "            for c3 in single_consonants:\n",
    "                if c3 != c2:\n",
    "                    multiple_consonants.append(c1 + '+' + c2 + '+' + c3)\n",
    "                    for c4 in single_consonants:\n",
    "                        if c4 != c3:\n",
    "                            multiple_consonants.append(c1 + '+' + c2 + '+' + c3 + '+' + c4)\n",
    "                            #for c5 in single_consonants:\n",
    "                            #    if c5 != c4:\n",
    "                            #        multiple_consonants.append(c1 + '+' + c2 + '+' + c3 + '+' + c4 + '+' + c5)\n",
    "\n",
    "consonant_list = single_consonants + multiple_consonants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bff449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_consonants(phonemes):\n",
    "    '''\n",
    "    >>> combine_consonants(['Y','IY','L','D'])\n",
    "    ['Y', 'IY', 'L+D']    \n",
    "    '''\n",
    "    phonemes_with_combined_consonants = []\n",
    "    P = len(phonemes)\n",
    "    i = 0\n",
    "    while i < P:\n",
    "        loop = True\n",
    "        while loop:\n",
    "            p1 = phonemes[i]\n",
    "            i += 1\n",
    "            if p1 in single_consonants:\n",
    "                if P > i:\n",
    "                    p2 = phonemes[i]\n",
    "                    i += 1\n",
    "                    if p2 in single_consonants:\n",
    "                        if P > i:\n",
    "                            p3 = phonemes[i]\n",
    "                            i += 1\n",
    "                            if p3 in single_consonants:\n",
    "                                if P > i:\n",
    "                                    p4 = phonemes[i]\n",
    "                                    i += 1\n",
    "                                    if p4 in single_consonants:\n",
    "                                        phonemes_with_combined_consonants.append(p1 + '+' + p2 + '+' + p3 + '+' + p4)\n",
    "                                        #if P > i:\n",
    "                                        #    p5 = phonemes[i]\n",
    "                                        #    i += 1\n",
    "                                        #    if p5 in single_consonants:\n",
    "                                        #        phonemes_with_combined_consonants.append(p1 + '+' + p2 + '+' + p3 + '+' + p4 + '+' + p5)\n",
    "                                        #    else:\n",
    "                                        #        phonemes_with_combined_consonants.append(p1 + '+' + p2 + '+' + p3 + '+' + p4)\n",
    "                                        #        phonemes_with_combined_consonants.append(p5)\n",
    "                                        #    break                                                \n",
    "                                        #else:\n",
    "                                        #    phonemes_with_combined_consonants.append(p1 + '+' + p2 + '+' + p3 + '+' + p4)\n",
    "                                        #    break\n",
    "                                    else:\n",
    "                                        phonemes_with_combined_consonants.append(p1 + '+' + p2 + '+' + p3)\n",
    "                                        phonemes_with_combined_consonants.append(p4)\n",
    "                                    break\n",
    "                                else:\n",
    "                                    phonemes_with_combined_consonants.append(p1 + '+' + p2 + '+' + p3)\n",
    "                                    break\n",
    "                            else:\n",
    "                                phonemes_with_combined_consonants.append(p1 + '+' + p2)\n",
    "                                phonemes_with_combined_consonants.append(p3)\n",
    "                                break\n",
    "                        else:\n",
    "                            phonemes_with_combined_consonants.append(p1 + '+' + p2)\n",
    "                            break\n",
    "                    else:\n",
    "                        phonemes_with_combined_consonants.append(p1)\n",
    "                        phonemes_with_combined_consonants.append(p2)\n",
    "                        break\n",
    "                else:\n",
    "                    phonemes_with_combined_consonants.append(p1)\n",
    "                    break\n",
    "            else:\n",
    "                phonemes_with_combined_consonants.append(p1)\n",
    "                break\n",
    "    \n",
    "    return phonemes_with_combined_consonants\n",
    "\n",
    "\n",
    "def separate_consonants(combined_consonants):\n",
    "    '''\n",
    "    Split up consonant compounds (\"I scream\" => \"ice cream\")?\n",
    "\n",
    "    English words by number of syllables: \n",
    "        https://en.wiktionary.org/wiki/Category:English_words_by_number_of_syllables\n",
    "        Ex: \"Honolulu\": 4 syllables, 8 phonemes (with or without combined consonants)\n",
    "        Ex: \"constructs\": 2 syllables, 10 phonemes or 5 combined (K, AA, N+S+T+R, UH, K+T+S)\n",
    "\n",
    "    >>> separate_consonants(['Y', 'IY', 'L+D'])\n",
    "    ['Y','IY','L','D']   \n",
    "    '''\n",
    "    if any(['+' in x for x in combined_consonants]):\n",
    "        separated_consonants = []\n",
    "        for c in combined_consonants:\n",
    "            if '+' in c:\n",
    "                separated_consonants.extend(c.split('+'))\n",
    "            else:\n",
    "                separated_consonants.append(c)\n",
    "    else:\n",
    "        separated_consonants = combined_consonants\n",
    "        \n",
    "    return separated_consonants\n",
    "\n",
    "                                        \n",
    "def separatER(phonemes):\n",
    "    '''\n",
    "    >>> separatER(['AE1', 'F', 'T', 'ER0'])  # 'after'\n",
    "    ['AE1', 'F', 'T', 'ER0', 'R']\n",
    "    '''\n",
    "    if any(['ER' in x for x in phonemes]):\n",
    "        new_pronunciation = []\n",
    "        for p in phonemes:\n",
    "            new_pronunciation.append(p)\n",
    "            if 'ER' in p:\n",
    "                new_pronunciation.append('R')\n",
    "    else:\n",
    "        new_pronunciation = phonemes\n",
    "        \n",
    "    return new_pronunciation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e1761",
   "metadata": {},
   "source": [
    "## Prepare / load dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd3a1b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dictionary_folder = \"data/dictionaries/\"\n",
    "filter_dictionary = 'LanguageTool'  #'english_words_py'  #'pyenchant'\n",
    "\n",
    "do_prepare_dictionary = False\n",
    "do_test_dictionaries = False\n",
    "\n",
    "if do_prepare_dictionary or do_test_dictionaries:\n",
    "    import nltk\n",
    "    import re\n",
    "    filter_words_file = \"data/dictionaries/filter_words.txt\"\n",
    "    filter_strings = ['.',',']\n",
    "    import language_tool_python\n",
    "    language_tool_object = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "\n",
    "def save_object(obj, pickle_file):\n",
    "    try:\n",
    "        with open(pickle_file, \"wb\") as f:\n",
    "            pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as ex:\n",
    "        print(\"Error during pickling object:\", ex)\n",
    "\n",
    "        \n",
    "def load_object(pickle_file):\n",
    "    try:\n",
    "        with open(pickle_file, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    except Exception as ex:\n",
    "        print(\"Error during unpickling object:\", ex)\n",
    "\n",
    "\n",
    "def filter_dictionary_words(words, consonants, pronunciations, stresses, \n",
    "                            filter_words, filter_strings, filter_dictionary='LanguageTool', \n",
    "                            verbose=False):\n",
    "    '''\n",
    "    Test filtering (with fake consonants, pronunciations, and stresses).\n",
    "    Make sure to import the necessary dictionaries below (see \"do_prepare_dictionary\").\n",
    "\n",
    "    >>> words = ['okay', 'k']\n",
    "    >>> filter_strings = ['.',',']\n",
    "    >>> fread_filter = open(filter_words_file, \"r\")\n",
    "    >>> filter_words = [x.strip() for x in fread_filter.readlines()]\n",
    "    >>> filter_dictionary_words(words, consonants=words, pronunciations=words, stresses=words, \n",
    "    >>>                         filter_words=filter_words, filter_strings=filter_strings, \n",
    "    >>>                         filter_dictionary='LanguageTool', verbose=False)\n",
    "    (['okay'], ['okay'], ['okay'], ['okay'], [])\n",
    "    '''\n",
    "    filtered_words = []\n",
    "    filtered_consonants = []\n",
    "    filtered_pronunciations = []\n",
    "    filtered_stresses = []\n",
    "    removed_words = []\n",
    "    for iword, word in enumerate(words):\n",
    "        if filter_dictionary == 'LanguageTool':\n",
    "            if (not any([x for x in language_tool_object.check(word) if x.ruleId == 'MORFOLOGIK_RULE_EN_US'])) and \\\n",
    "                (word not in filter_words) and \\\n",
    "                (word not in filtered_words) and \\\n",
    "                all([x not in word for x in filter_strings]):\n",
    "                    filtered_words.append(word)\n",
    "                    filtered_consonants.append(consonants[iword])\n",
    "                    filtered_pronunciations.append(pronunciations[iword])\n",
    "                    filtered_stresses.append(stresses[iword])\n",
    "        elif filter_dictionary == 'pyenchant':\n",
    "            if (enchant_dict.check(word) or enchant_dict.check(word.capitalize())) and \\\n",
    "                (word not in filter_words) and \\\n",
    "                (word not in filtered_words) and \\\n",
    "                all([x not in word for x in filter_strings]):\n",
    "                    filtered_words.append(word)\n",
    "                    filtered_consonants.append(consonants[iword])\n",
    "                    filtered_pronunciations.append(pronunciations[iword])\n",
    "                    filtered_stresses.append(stresses[iword])\n",
    "        elif filter_dictionary == 'english_words_py':\n",
    "            if ((word in english_words_set or \\\n",
    "                    (word[:-1] in english_words_set and word[-1] == 's')) or \\\n",
    "                (word.capitalize() in english_words_set or \\\n",
    "                    (word.capitalize()[:-1] in english_words_set and word.capitalize()[-1] == 's'))\n",
    "               ) and \\\n",
    "                (word not in filter_words) and \\\n",
    "                (word not in filtered_words) and \\\n",
    "                all([x not in word for x in filter_strings]):\n",
    "                    filtered_words.append(word)\n",
    "                    filtered_consonants.append(consonants[iword])\n",
    "                    filtered_pronunciations.append(pronunciations[iword])\n",
    "                    filtered_stresses.append(stresses[iword])\n",
    "        else:\n",
    "            removed_words.append(word)\n",
    "    \n",
    "    if verbose and removed_words != []:\n",
    "        print('{0} retained words, {1} removed words'.format(len(filtered_words),len(removed_words)))\n",
    "\n",
    "    return filtered_words, filtered_consonants, filtered_pronunciations, filtered_stresses, removed_words\n",
    "\n",
    "\n",
    "def prepare_dictionary(filter_dictionary, filter_words_file, filter_strings, dictionary_folder, consonant_list):\n",
    "    '''\n",
    "    Filter CMU Pronunciation dictionary words and pronunciations.\n",
    "    Use a second dictionary of common words (example below from LanguageTool).\n",
    "    Make sure to import the necessary dictionaries below (see \"do_prepare_dictionary\").\n",
    "\n",
    "    >>> index=48792\n",
    "    >>> print(all_words[index], all_consonants[index])\n",
    "    thirty ['TH','ER','R+D','IY'] \n",
    "    \n",
    "    Check dictionary entry:\n",
    "    >>> inword = 'ill-behaved' #'thirty'\n",
    "    >>> inpron = ['TH','ER','R+D','IY']\n",
    "    >>> print('{0}'.format(inword in all_words))\n",
    "    >>> print('{0}'.format(inpron in all_pronunciations))\n",
    "    >>> all_pronunciations[all_words.index('thirty')]\n",
    "    '''\n",
    "    cmu_entries = nltk.corpus.cmudict.entries()\n",
    "    cmu_words = []\n",
    "    cmu_consonants = []\n",
    "    cmu_pronunciations = []\n",
    "    cmu_pronunciations_stress = []\n",
    "    cmu_stresses = []\n",
    "    for cmu_word, cmu_pronunciation_stress in cmu_entries:\n",
    "        if cmu_word not in cmu_words:\n",
    "            cmu_words.append(cmu_word.strip())\n",
    "            if any(['ER' in x for x in cmu_pronunciation_stress]):\n",
    "                cmu_pronunciation_stress = separatER(cmu_pronunciation_stress)\n",
    "            cmu_pronunciation_stress = combine_consonants(cmu_pronunciation_stress)\n",
    "            cmu_pronunciation_no_stress = [re.sub(r'\\d+', '', x) for x in cmu_pronunciation_stress]\n",
    "            cmu_pronunciations.append(cmu_pronunciation_no_stress)\n",
    "            cmu_consonants.append([x for x in cmu_pronunciation_no_stress if x in consonant_list])\n",
    "            cmu_stresses.append([re.sub(r'[A-Za-z\\+]', '', x) for x in cmu_pronunciation_stress])         \n",
    "            #print(cmu_word, cmu_pronunciation_no_stress)\n",
    "\n",
    "    print('Filter the CMU dictionary...')\n",
    "\n",
    "    # Load filter words\n",
    "    fread_filter = open(filter_words_file, \"r\")\n",
    "    filter_words = [x.strip() for x in fread_filter.readlines()]\n",
    "\n",
    "    all_words, all_consonants, all_pronunciations, all_stresses, nonwords = filter_dictionary_words(cmu_words, \n",
    "        cmu_consonants, cmu_pronunciations, cmu_stresses, \n",
    "        filter_words, filter_strings, filter_dictionary, verbose=False)    \n",
    "\n",
    "    save_object(all_words, dictionary_folder + 'words_{0}.pkl'.format(filter_dictionary))\n",
    "    save_object(all_consonants, dictionary_folder + 'consonants_{0}.pkl'.format(filter_dictionary))\n",
    "    save_object(all_pronunciations, dictionary_folder + 'pronunciations_{0}.pkl'.format(filter_dictionary))\n",
    "    save_object(all_stresses, dictionary_folder + 'stresses_{0}.pkl'.format(filter_dictionary))\n",
    "\n",
    "\n",
    "# Prepare or load dictionary\n",
    "if do_prepare_dictionary:\n",
    "    if filter_dictionary == 'pyenchant':\n",
    "        import enchant\n",
    "        enchant_dict = enchant.Dict(\"en_US\")\n",
    "    elif filter_dictionary == 'english_words_py':\n",
    "        from english_words import english_words_set\n",
    "    prepare_dictionary(filter_dictionary, filter_words_file, filter_strings, dictionary_folder, consonant_list)    \n",
    "else:\n",
    "    all_words = load_object(dictionary_folder + 'words_{0}.pkl'.format(filter_dictionary))\n",
    "    all_consonants = load_object(dictionary_folder + 'consonants_{0}.pkl'.format(filter_dictionary))\n",
    "    all_pronunciations = load_object(dictionary_folder + 'pronunciations_{0}.pkl'.format(filter_dictionary))\n",
    "    all_stresses = load_object(dictionary_folder + 'stresses_{0}.pkl'.format(filter_dictionary))\n",
    "    \n",
    "\n",
    "# Test different dictionaries\n",
    "if do_test_dictionaries:\n",
    "\n",
    "    cmu_entries = nltk.corpus.cmudict.entries()\n",
    "\n",
    "    import enchant\n",
    "    enchant_dict = enchant.Dict(\"en_US\")\n",
    "    #pip install cmudict\n",
    "    #nltk.download('cmudict')\n",
    "    #pip install pyenchant\n",
    "\n",
    "    # english-words-py (https://pypi.org/project/english-words/)\n",
    "    # \"Contains sets of English words from svnweb.freebsd.org/csrg/share/dict/. \n",
    "    # This is up to date with revision 61569 of their words list.\"\n",
    "    from english_words import english_words_set\n",
    "\n",
    "    # Most Common English Words (https://github.com/dolph/dictionary)\n",
    "    # \"enable1.txt (172,819), the more verbose version of the Official Scrabble Player's Dictionary \n",
    "    # (which is limited to words of 8 letters or less)\"\n",
    "    # \"popular.txt (25,322) represents the common subset of words found in both enable1.txt and Wiktionary's \n",
    "    # word frequency lists, which are in turn compiled by statistically analyzing a sample of 29 million \n",
    "    # words used in English TV and movie scripts.\"\n",
    "    enable1 = [line.rstrip() for line in open('data/dictionaries/enable1.txt')]\n",
    "    popular = [line.rstrip() for line in open('data/dictionaries/popular.txt')]\n",
    "\n",
    "    # NLTK words corpus:\n",
    "    #nltk.download('words')\n",
    "    from nltk.corpus import words\n",
    "    nltk_wordset = set(words.words())\n",
    "\n",
    "    # Wiktionary Word Frequency_lists (https://en.wiktionary.org/wiki/Wiktionary:Frequency_lists#English)\n",
    "    #https://gist.github.com/h3xx/1976236\n",
    "    \n",
    "    print('nltk_wordset:      {0}'.format(len(nltk_wordset)))\n",
    "    print('enable1:           {0}'.format(len(enable1)))\n",
    "    print('pyenchant:         {0}'.format('?')) #len(enchant_dict.values())))\n",
    "    print('english-words-py:  {0}'.format(len(english_words_set)))\n",
    "    print('popular:           {0}'.format(len(popular)))\n",
    "    print('LanguageTool (LT): {0}'.format('?'))\n",
    "    print('-------------------------------------------------------')\n",
    "    print('CMU:               {0}'.format(len(cmu_entries)))\n",
    "    print('CMU and LT:        {0}'.format(len(all_words)))\n",
    "    print()\n",
    "    test_words = [\"can't\", 'geese', 'shelves', 'Thai', 'thai', 'e.', 'bott', 'bitter', 'used']\n",
    "    for test_word in test_words:\n",
    "        print(test_word)\n",
    "        print('        NLTK words corpus:  {0}'.format(test_word in nltk_wordset))\n",
    "        print('        enable frequency:   {0}'.format(test_word in enable1))\n",
    "        print('        pyenchant spelling: {0}'.format(enchant_dict.check(test_word)))\n",
    "        print('        english-words-py:   {0}'.format(test_word in english_words_set))\n",
    "        print('        popular frequency:  {0}'.format(test_word in popular))\n",
    "        print('        LanguageTool:       {0}'.format(not any([x for x in language_tool_object.check(test_word) if x.ruleId == 'MORFOLOGIK_RULE_EN_US'])))\n",
    "        print('-------------------------------------------------------')\n",
    "        print('        CMU:                {0}'.format(any([x for x,y in cmu_entries if test_word == x])))\n",
    "        print('        CMU and LT:         {0}'.format(test_word in all_words))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b349669b",
   "metadata": {},
   "source": [
    "    nltk_wordset:      235892\n",
    "    enable1:           172823\n",
    "    pyenchant:         ?\n",
    "    english-words-py:  25487\n",
    "    popular:           25322\n",
    "    LanguageTool (LT): ?\n",
    "    -------------------------------------------------------\n",
    "    CMU:               133737\n",
    "    CMU and LT:        54117\n",
    "    \n",
    "                                can't    geese    shelves  Thai     thai     e.       bott     bitter   used\n",
    "            NLTK words corpus:  False    False    False    True     False    False    True     True     True\n",
    "            enable frequency:   False    True     True     False    False    False    True     True     True\n",
    "            pyenchant spelling: True     True     True     True     False    True     True     True     True\n",
    "            english-words-py:   True     True     False    True     False    False    False    False    False\n",
    "            popular frequency:  False    True     True     False    False    False    False    True     True\n",
    "            LanguageTool:       True     True     True     True     False    True     False    True     True\n",
    "            ------------------------------------------------------------------------------------------------\n",
    "            CMU:                True     True     True     False    True     True     True     True     True\n",
    "            CMU & LanguageTool: True     True     True     False    False    False    False    True     True\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a7cbdb",
   "metadata": {},
   "source": [
    "## Code to convert text to phonemes (and stresses and number of syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50406f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from g2p_en import G2p  # pip install g2p_en\n",
    "word_to_phonemes = G2p()\n",
    "\n",
    "# Code to count syllables\n",
    "# https://datascience.stackexchange.com/questions/23376/how-to-get-the-number-of-syllables-in-a-word\n",
    "syllable_vowel_runs = re.compile(\"[aeiouy]+\", flags=re.I)\n",
    "syllable_exceptions = re.compile(\n",
    "    # fixes trailing e issues:\n",
    "    # smite, scared\n",
    "    \"[^aeiou]e[sd]?$|\"\n",
    "    # fixes adverbs:\n",
    "    # nicely\n",
    "    + \"[^e]ely$\",\n",
    "    flags=re.I\n",
    ")\n",
    "additional_syllables = re.compile(\n",
    "    # fixes incorrect subtractions from exceptions:\n",
    "    # smile, scarred, raises, fated\n",
    "    \"[^aeioulr][lr]e[sd]?$|[csgz]es$|[td]ed$|\"\n",
    "    # fixes miscellaneous issues:\n",
    "    # flying, piano, video, prism, fire, evaluate\n",
    "    + \".y[aeiou]|ia(?!n$)|eo|ism$|[^aeiou]ire$|[^gq]ua\",\n",
    "    flags=re.I\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cd3c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(word, syllable_vowel_runs=syllable_vowel_runs, syllable_exceptions=syllable_exceptions, \n",
    "                    additional_syllables=additional_syllables):\n",
    "    '''\n",
    "    Count the number of syllables in a word.\n",
    "\n",
    "    >>> word = 'lovely'\n",
    "    >>> syllable_vowel_runs = re.compile('[aeiouy]+', re.IGNORECASE)\n",
    "    >>> syllable_exceptions = re.compile('[^aeiou]e[sd]?$|[^e]ely$', re.IGNORECASE) \n",
    "    >>> additional_syllables = re.compile('[^aeioulr][lr]e[sd]?$|[csgz]es$|[td]ed$|.y[aeiou]|ia(?!n$)|eo|ism$|[^aeiou]ire$|[^gq]ua', re.IGNORECASE)\n",
    "    >>> count_syllables(word)\n",
    "    2\n",
    "    '''\n",
    "    vowel_runs = len(syllable_vowel_runs.findall(word))\n",
    "    exceptions = len(syllable_exceptions.findall(word))\n",
    "    additional = len(additional_syllables.findall(word))\n",
    "\n",
    "    return max(1, vowel_runs - exceptions + additional)\n",
    "\n",
    "\n",
    "def words_to_sounds(words, phoneme_list, consonant_list):\n",
    "    '''\n",
    "    From a list of words, return phonemes, consonants, stresses, and number of syllables.\n",
    "\n",
    "    Output: phonemes, consonants, stresses, numbers of syllables\n",
    "    \n",
    "    >>> sentence1 = 'A witch is itself conscious or without agency.'\n",
    "    >>> sentence2 = 'Uh, which is it, self-conscious or without agency?'\n",
    "    >>> words = sentence1.split('-')\n",
    "    >>> words_to_sounds(words, phoneme_list, consonant_list)\n",
    "    (['AH','W','IH','CH','IH','Z','IH','T+S','EH','L+F',\n",
    "      'K','AA','N+SH','AH','S','AO','R','W','IH','TH','AW','T',\n",
    "      'EY','JH','AH','N+S','IY'],\n",
    "     ['W','CH','Z','T+S','L+F','K','N+SH','S',\n",
    "      'R','W','TH','T','JH','N+S'],\n",
    "     ['0','','1','','1','','0','+','1','+','','1','+',\n",
    "      '0','','1','','','0','','1','','1','','0','+','0'],\n",
    "     13)    \n",
    "    >>> words = sentence2.split('-')\n",
    "    >>> words_to_sounds(words, phoneme_list, consonant_list)\n",
    "    (['AH','W','IH','CH','IH','Z','IH','T','S','EH','L+F',\n",
    "      'K','AA','N+SH','AH','S','AO','R','W','IH','TH','AW','T',\n",
    "      'EY','JH','AH','N+S','IY'],\n",
    "     ['W','CH','Z','T','S','L+F','K','N+SH','S',\n",
    "      'R','W','TH','T','JH','N+S'],\n",
    "     ['1','','1','','1','','1','','','1','+','','1','+',\n",
    "      '0','','1','','','0','','1','','1','','0','+','0'],\n",
    "     13)    \n",
    "    '''\n",
    "\n",
    "    phonemes = []\n",
    "    stresses = []\n",
    "    syllables = 0\n",
    "    for word in words:\n",
    "\n",
    "        # Extract phonemes per word (choose the first version of the phoneme)\n",
    "        #     :: multiple pronunciations: pronouncing.phones_for_word(word) \n",
    "        phonemes_and_stresses_for_word = word_to_phonemes(word)\n",
    "        if any(['ER' in x for x in phonemes_and_stresses_for_word]):\n",
    "            phonemes_and_stresses_for_word = separatER(phonemes_and_stresses_for_word)\n",
    "        phonemes_and_stresses_for_word = combine_consonants(phonemes_and_stresses_for_word)\n",
    "        phonemes_for_word = [re.sub(r'\\d+', '', x) for x in phonemes_and_stresses_for_word \n",
    "                             if re.sub(r'\\d+', '', x) in phoneme_list or x in consonant_list]\n",
    "        stresses_for_word = [re.sub(r\"(?:[A-Z])\",'', x) for x in phonemes_and_stresses_for_word\n",
    "                             if re.sub(r'\\d+', '', x) in phoneme_list or x in consonant_list]\n",
    "\n",
    "        phonemes += phonemes_for_word  \n",
    "        stresses += stresses_for_word\n",
    "        syllables += count_syllables(word)\n",
    "\n",
    "    consonants = [x for x in phonemes if x in consonant_list] \n",
    "\n",
    "    return phonemes, consonants, stresses, syllables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1758a92",
   "metadata": {},
   "source": [
    "## Code to convert phonemes to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b6962bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_numbers(numbers):\n",
    "    unique = []\n",
    "    for number in numbers:\n",
    "        if number not in unique:\n",
    "            unique.append(number)\n",
    "    return unique\n",
    "\n",
    "\n",
    "def phonemes_to_words(phonemes, all_words, all_pronunciations, all_consonants, consonant_list, \n",
    "                      just_consonants=False, max_phonemes_per_word=25, ignore_words=None):\n",
    "    '''\n",
    "    Find all words that sound like each sequence of phonemes from a phoneme list.\n",
    "    \n",
    "    Generate a list of words (with start and stop indices) from a sequential list of phonemes,\n",
    "    by concatenating sequences of the phonemes and searching in CMU's Pronunciation Dictionary.\n",
    "    \n",
    "    max_phonemes_per_word:\n",
    "    n-syllable words without combined consonants <= 5n phonemes\n",
    "    n-syllable words with combined consonants <= 2n + 1 phonemes\n",
    "    5-syllable words: <=25 phonemes, <=11 with combined consonants\n",
    "    \n",
    "    >>> # input_sentence = 'Uh, which is it, self-conscious or without agency?'\n",
    "    >>> # words = input_sentence.split('-')  #words = [re.sub(r'[^\\'A-Za-z\\-]', '', x).lower() for x in words]\n",
    "    >>> # phonemes, consonants, stresses, nsyllables = words_to_sounds(words, phoneme_list, consonant_list)\n",
    "    >>> phonemes = ['AH','W','IH','CH','IH','Z','IH','T','S','EH','L+F',\n",
    "                    'K','AA','N+SH','AH','S','AO','R','W','IH','TH','AW','T',\n",
    "                    'EY','JH','AH','N+S','IY']    \n",
    "    >>> just_consonants = False\n",
    "    >>> phonemes_to_words(phonemes, all_words, all_pronunciations, all_consonants, consonant_list, \n",
    "                          just_consonants, max_phonemes_per_word=25, ignore_words=None)\n",
    "\n",
    "    [['a', 0, 0],['uh', 0, 0],['uhh', 0, 0],['which', 1, 3],['witch', 1, 3],[\"which's\", 1, 5],\n",
    "    [\"witch's\", 1, 5],['itch', 2, 3],['is', 4, 5],['it', 6, 7],[\"it's\", 6, 8],\n",
    "    ['its', 6, 8],['itself', 6, 10],['self', 8, 10],['eh', 9, 9],['elf', 9, 10],\n",
    "    ['conscious', 11, 15],['ah', 12, 12],['ahh', 12, 12],['awe', 12, 12],\n",
    "    ['uh', 14, 14],['uhh', 14, 14],['us', 14, 15],['saw', 15, 16],['soar', 15, 17],\n",
    "    ['sore', 15, 17],['aw', 16, 16],['oar', 16, 17],['or', 16, 17],['ore', 16, 17],\n",
    "    ['withe', 18, 20],['without', 18, 22],['out', 21, 22],['age', 23, 24],\n",
    "    ['agency', 23, 27],['uh', 25, 25],['uhh', 25, 25]]\n",
    "     \n",
    "    >>> just_consonants = True\n",
    "    >>> phonemes_to_words(phonemes, all_words, all_pronunciations, all_consonants, consonant_list, \n",
    "                          just_consonants, max_phonemes_per_word=25, ignore_words=None)\n",
    "\n",
    "    [['away', 0, 1],['way', 0, 1],['we', 0, 1],['wee', 0, 1],['weigh', 0, 1],...\n",
    "     ['which', 0, 3],['witch', 0, 3],['watches', 0, 5],[\"which's\", 0, 5],...\n",
    "     ['conscious', 11, 15],['ac', 14, 15],['ace', 14, 15],['ass', 14, 15],...\n",
    "     ['agency', 23, 26],['age', 24, 24],['edge', 24, 24],['edgy', 24, 24],\n",
    "     ...\n",
    "    ]]\n",
    "    '''\n",
    "\n",
    "    words_starts_stops = []    \n",
    "    start = 0\n",
    "    unique_stops = [-1]\n",
    "    nphonemes = len(phonemes)\n",
    "    while start < nphonemes:\n",
    "\n",
    "        # For each subsequence of phonemes\n",
    "        consonant_subsets = []\n",
    "        max_stop = min(nphonemes + 1, start + max_phonemes_per_word + 2) \n",
    "        for stop in range(start + 1, max_stop):\n",
    "\n",
    "            phoneme_subset = phonemes[start:stop]\n",
    "            phoneme_subset = combine_consonants(phoneme_subset)\n",
    "\n",
    "            # Find words with matching consonants:\n",
    "            if just_consonants:\n",
    "                consonant_subset = [x for x in phoneme_subset if x in consonant_list]\n",
    "                if consonant_subset != [] and consonant_subset not in consonant_subsets:\n",
    "                    consonant_subsets.append(consonant_subset)\n",
    "                    try:\n",
    "                        indices = [i for i,x in enumerate(all_consonants) if x == consonant_subset]\n",
    "                        for index in indices:\n",
    "                            words_starts_stops.append([all_words[index], start, stop - 1])\n",
    "                    except: pass\n",
    "\n",
    "            # Find words with fully matching pronunciations:\n",
    "            else:\n",
    "                try:\n",
    "                    indices = [i for i,x in enumerate(all_pronunciations) if x == phoneme_subset]\n",
    "                    for index in indices:\n",
    "                        words_starts_stops.append([all_words[index], start, stop - 1])\n",
    "                except: pass\n",
    "\n",
    "        start += 1\n",
    "                \n",
    "    if ignore_words:\n",
    "        words_starts_stops = [x for x in words_starts_stops if x[0] not in ignore_words]\n",
    "\n",
    "    return words_starts_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d01fb2",
   "metadata": {},
   "source": [
    "## Code to construct word sequences with matching phoneme stop and start indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "313eab62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def flatten_list(nested_list):\n",
    "    '''\n",
    "    Flatten so that there are no tuples or lists within the list.\n",
    "    \n",
    "    >>> nested_list = [('e1d1', ('e1d2'), ['e2d1']), 'e3d0', [], ['e5d1']]\n",
    "    >>> flatten_list(nested_list)\n",
    "    ['e1d1', 'e1d2', 'e2d1', 'e3d0', 'e5d1']\n",
    "    '''\n",
    "    result=[]\n",
    "    if nested_list != []:\n",
    "        for element in nested_list:\n",
    "            if isinstance(element, list) or isinstance(element, tuple):\n",
    "                result.extend(flatten_list(element))\n",
    "            else:\n",
    "                result.append(element)\n",
    "\n",
    "    return result\n",
    "\n",
    "            \n",
    "def flatten_to_sublists_of_strings(nested_list):\n",
    "    '''\n",
    "    Flatten list to strings and sublists of strings.\n",
    "\n",
    "    >>> nested_list = [[[], '0', ('1',11,12), ('2',21,22), ['3',31,32]], [['4',41,42]]]\n",
    "    >>> flatten_to_sublists_of_strings(nested_list)\n",
    "    [[], '0', ['1', 11, 12], ['2', 21, 22], ['3', 31, 32], ['4', 41, 42]]\n",
    "    \n",
    "    >>> # input_sentence = 'Uh, which is it, self-conscious or without agency?'\n",
    "    >>> # words = input_sentence.split('-')  #words = [re.sub(r'[^\\'A-Za-z\\-]', '', x).lower() for x in words]\n",
    "    >>> # phonemes, consonants, stresses, nsyllables = words_to_sounds(words, phoneme_list, consonant_list)\n",
    "    >>> # words_starts_stops = phonemes_to_words(phonemes, all_words, all_pronunciations, all_consonants, \n",
    "        #                                        consonant_list, just_consonants, max_phonemes_per_word, \n",
    "        #                                        ignore_words)\n",
    "    >>> # words_starts_stops = flatten_to_sublists_of_strings(words_starts_stops) \n",
    "    >>> # words_by_start, stops, unique_starts, unique_stops, max_start, max_stop = organize_words_by_start(words_starts_stops)\n",
    "\n",
    "    >>> words_by_start = [['a', 0, 0],['uh', 0, 0],['uhh', 0, 0],['which', 1, 3],['witch', 1, 3],[\"which's\", 1, 5],\n",
    "     [\"witch's\", 1, 5],['itch', 2, 3],['is', 4, 5],['it', 6, 7],[\"it's\", 6, 8],\n",
    "     ['its', 6, 8],['itself', 6, 10],['self', 8, 10],['eh', 9, 9],['elf', 9, 10],\n",
    "     ['conscious', 11, 15],['ah', 12, 12],['ahh', 12, 12],['awe', 12, 12],\n",
    "     ['uh', 14, 14],['uhh', 14, 14],['us', 14, 15],['saw', 15, 16],['soar', 15, 17],\n",
    "     ['sore', 15, 17],['aw', 16, 16],['oar', 16, 17],['or', 16, 17],['ore', 16, 17],\n",
    "     ['withe', 18, 20],['without', 18, 22],['out', 21, 22],['age', 23, 24],\n",
    "     ['agency', 23, 27],['uh', 25, 25],['uhh', 25, 25]] \n",
    "    \n",
    "    >>> flatten_to_sublists_of_strings(words_by_start)\n",
    "\n",
    "    [['a', 0, 0],['uh', 0, 0],['uhh', 0, 0],['which', 1, 3],['witch', 1, 3],\n",
    "     [\"which's\", 1, 5],[\"witch's\", 1, 5],['itch', 2, 3],['is', 4, 5],['it', 6, 7],[\"it's\", 6, 8],\n",
    "     ['its', 6, 8],['itself', 6, 10],['self', 8, 10],['eh', 9, 9],['elf', 9, 10],\n",
    "     ['conscious', 11, 15],['ah', 12, 12],['ahh', 12, 12],['awe', 12, 12],\n",
    "     ['uh', 14, 14],['uhh', 14, 14],['us', 14, 15],['saw', 15, 16],['soar', 15, 17],\n",
    "     ['sore', 15, 17],['aw', 16, 16],['oar', 16, 17],['or', 16, 17],['ore', 16, 17],\n",
    "     ['withe', 18, 20],['without', 18, 22],['out', 21, 22],['age', 23, 24],\n",
    "     ['agency', 23, 27],['uh', 25, 25],['uhh', 25, 25]]    \n",
    "     '''\n",
    "    \n",
    "    result=[]\n",
    "    if nested_list == []:\n",
    "        result.extend([[]])\n",
    "    else:\n",
    "        if not any([isinstance(x, list)  for x in nested_list]) and \\\n",
    "           not any([isinstance(x, tuple) for x in nested_list]):\n",
    "            y=[]\n",
    "            for x in nested_list:\n",
    "                y.append(x)\n",
    "            result.append(y)\n",
    "        else:\n",
    "            for element in nested_list:\n",
    "                if isinstance(element, str):\n",
    "                    result.extend(element)\n",
    "                elif isinstance(element, list) or isinstance(element, tuple):\n",
    "                    if element == []:\n",
    "                        result.extend([[]])\n",
    "                    else:\n",
    "                        result.extend(flatten_to_sublists_of_strings(element)) \n",
    "    \n",
    "    return result\n",
    "\n",
    "            \n",
    "def find_words_with_start_index(word_start_stop_list, start_index):\n",
    "    '''\n",
    "    Find words in a word list with start and stop indices that start at index start_index.\n",
    "    '''\n",
    "    start_words = []\n",
    "    starts = []\n",
    "    stops = []\n",
    "    for word, start, stop in word_start_stop_list:\n",
    "        if start == start_index and start != []:\n",
    "            start_words.append(word)\n",
    "            starts.append(start)\n",
    "            stops.append(stop)\n",
    "            \n",
    "    return start_words, starts, stops\n",
    "\n",
    "\n",
    "def organize_words_by_start(words_list):\n",
    "    '''\n",
    "    Organize a list of words (and corresponding start and stop indices) by start index.\n",
    "    Output: words_by_start, stops, unique_starts, x, y, max_stop\n",
    "    \n",
    "    >>> # input_sentence = 'Uh, which is it, self-conscious or without agency?'\n",
    "    >>> # words = input_sentence.split('-')  #words = [re.sub(r'[^\\'A-Za-z\\-]', '', x).lower() for x in words]\n",
    "    >>> # phonemes, consonants, stresses, nsyllables = words_to_sounds(words, phoneme_list, consonant_list)\n",
    "    >>> # words_starts_stops = phonemes_to_words(phonemes, all_words, all_pronunciations, all_consonants, \n",
    "        #                                        consonant_list, just_consonants, max_phonemes_per_word, \n",
    "        #                                        ignore_words)\n",
    "    >>> # words_starts_stops = flatten_to_sublists_of_strings(words_starts_stops) \n",
    "\n",
    "    >>> words_starts_stops = [['a', 0, 0],['uh', 0, 0],['uhh', 0, 0],['which', 1, 3],['witch', 1, 3],\n",
    "     [\"which's\", 1, 5],[\"witch's\", 1, 5],['itch', 2, 3],['is', 4, 5],['it', 6, 7],[\"it's\", 6, 8],\n",
    "     ['its', 6, 8],['itself', 6, 10],['self', 8, 10],['eh', 9, 9],['elf', 9, 10],\n",
    "     ['conscious', 11, 15],['ah', 12, 12],['ahh', 12, 12],['awe', 12, 12],\n",
    "     ['uh', 14, 14],['uhh', 14, 14],['us', 14, 15],['saw', 15, 16],['soar', 15, 17],\n",
    "     ['sore', 15, 17],['aw', 16, 16],['oar', 16, 17],['or', 16, 17],['ore', 16, 17],\n",
    "     ['withe', 18, 20],['without', 18, 22],['out', 21, 22],['age', 23, 24],\n",
    "     ['agency', 23, 27],['uh', 25, 25],['uhh', 25, 25]]    \n",
    "\n",
    "    >>> organize_words_by_start(words_starts_stops)\n",
    "\n",
    "    ([['a', 'uh', 'uhh'],['which', 'witch', \"which's\", \"witch's\"],['itch'],[],['is'],[],\n",
    "      ['it', \"it's\", 'its', 'itself'],[],['self'],['eh', 'elf'],[],['conscious'],\n",
    "      ['ah', 'ahh', 'awe'],[],['uh', 'uhh', 'us'],['saw', 'soar', 'sore'],\n",
    "      ['aw', 'oar', 'or', 'ore'],[],['withe', 'without'],[],[],['out'],[],\n",
    "      ['age', 'agency'],[],['uh', 'uhh']],\n",
    "     [[0, 0, 0],[3, 3, 5, 5],[3],[],[5],[],[7, 8, 8, 10],[],[10],[9, 10],[],\n",
    "      [15],[12, 12, 12],[],[14, 14, 15],[16, 17, 17],[16, 17, 17, 17],[],\n",
    "      [20, 22],[],[],[22],[],[24, 27],[],[25, 25]],\n",
    "     [0, 1, 2, 4, 6, 8, 9, 11, 12, 14, 15, 16, 18, 21, 23, 25],\n",
    "     [0, 3, 5, 7, 8, 10, 9, 15, 12, 14, 16, 17, 20, 22, 24, 27, 25],\n",
    "     25,27)    \n",
    "    \n",
    "    '''\n",
    "\n",
    "    if not isinstance(words_list[0], list) and not isinstance(words_list[0], tuple):\n",
    "        words_list = [words_list]\n",
    "        \n",
    "    # Get unique starts and stops, and max start and stop\n",
    "    words2 = []\n",
    "    starts2 = []\n",
    "    stops2 = []\n",
    "    for word, start, stop in words_list:\n",
    "        words2.append(word)\n",
    "        starts2.append(start)\n",
    "        stops2.append(stop)\n",
    "    unique_starts = get_unique_numbers(starts2)\n",
    "    unique_stops = get_unique_numbers(stops2)\n",
    "    max_start = max(get_unique_numbers(starts2))\n",
    "    max_stop = max(get_unique_numbers(stops2))\n",
    "\n",
    "    # Words organized by start index\n",
    "    words_by_start = []\n",
    "    stops = []\n",
    "    for start_index in range(max_start + 1):\n",
    "        start_words, istarts, istops = find_words_with_start_index(words_list, start_index)\n",
    "        words_by_start.append(start_words)\n",
    "        stops.append(istops)        \n",
    "\n",
    "    return words_by_start, stops, unique_starts, unique_stops, max_start, max_stop\n",
    "\n",
    "\n",
    "def concatenate_lists(list_of_lists1, list_of_lists2):\n",
    "    result = []\n",
    "    for item1, item2 in zip(list_of_lists1, list_of_lists2):\n",
    "        if isinstance(item1, str) and isinstance(item2, list):\n",
    "            for element in item2:\n",
    "                result.append((item1, element))\n",
    "        elif isinstance(item1, list) and isinstance(item2, list):\n",
    "            result.append((item1 + item2))\n",
    "        elif isinstance(item1, tuple) and isinstance(item2, list):\n",
    "            result.append((list(item1) + item2))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def concatenate_word_pairs(prev_words, prev_stops, words_by_start, stops_by_start, unique_starts):\n",
    "    '''\n",
    "    Concatenate word pairs where the stop index of the first word matches the start index of the next word.\n",
    "\n",
    "    >>> # input_sentence = 'Uh, which is it, self-conscious or without agency?'\n",
    "    >>> # words = input_sentence.split('-')  #words = [re.sub(r'[^\\'A-Za-z\\-]', '', x).lower() for x in words]\n",
    "    >>> # phonemes, consonants, stresses, nsyllables = words_to_sounds(words, phoneme_list, consonant_list)\n",
    "    >>> # words_starts_stops = phonemes_to_words(phonemes, all_words, all_pronunciations, all_consonants, \n",
    "        #                                        consonant_list, just_consonants, max_phonemes_per_word, \n",
    "        #                                        ignore_words)\n",
    "    >>> # words_starts_stops = flatten_to_sublists_of_strings(words_starts_stops) \n",
    "    >>> # words_by_start, stops_by_start, unique_starts, unique_stops, max_start, max_stop = organize_words_by_start(words_starts_stops)\n",
    "    >>> prev_words = ['a', 'uh', 'uhh']\n",
    "    >>> prev_stops = [0, 0, 0]\n",
    "    >>> words_by_start = [['a', 'uh', 'uhh'],['which', 'witch', \"which's\", \"witch's\"],['itch'],[],['is'],[],\n",
    "      ['it', \"it's\", 'its', 'itself'],[],['self'],['eh', 'elf'],[],['conscious'],\n",
    "      ['ah', 'ahh', 'awe'],[],['uh', 'uhh', 'us'],['saw', 'soar', 'sore'],\n",
    "      ['aw', 'oar', 'or', 'ore'],[],['withe', 'without'],[],[],['out'],[],\n",
    "      ['age', 'agency'],[],['uh', 'uhh']]\n",
    "    >>> stops_by_start = [[0, 0, 0],[3, 3, 5, 5],[3],[],[5],[],[7, 8, 8, 10],[],[10],[9, 10],[],[15],[12, 12, 12],[],[14, 14, 15],[16, 17, 17],\n",
    "                          [16, 17, 17, 17],[],[20, 22],[],[],[22],[],[24, 27],[],[25, 25]]\n",
    "    >>> unique_starts = [0, 1, 2, 4, 6, 8, 9, 11, 12, 14, 15, 16, 18, 21, 23, 25]\n",
    "    >>> unique_stops = [0, 3, 5, 7, 8, 10, 9, 15, 12, 14, 16, 17, 20, 22, 24, 27, 25]\n",
    "    >>> concatenate_word_pairs(prev_words, prev_stops, words_by_start, stops_by_start, unique_starts)\n",
    "\n",
    "    ([['a', 'which'],['a', 'witch'],['a', \"which's\"],['a', \"witch's\"],\n",
    "      ['uh', 'which'],['uh', 'witch'],['uh', \"which's\"],['uh', \"witch's\"],\n",
    "      ['uhh', 'which'],['uhh', 'witch'],['uhh', \"which's\"],['uhh', \"witch's\"]],\n",
    "     [3, 3, 5, 5, 3, 3, 5, 5, 3, 3, 5, 5])\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # Initialize / format words\n",
    "    new_words = []\n",
    "    new_stops = []\n",
    "    words1 = prev_words\n",
    "    stops1 = prev_stops\n",
    " \n",
    "    # For each word that starts at a given index\n",
    "    for iword1, word1 in enumerate(words1):\n",
    "\n",
    "        # Find words that start after that word stops\n",
    "        word1_stop = stops1[iword1]\n",
    "        word2_start = word1_stop + 1\n",
    "        if word2_start in unique_starts:\n",
    "            words2 = words_by_start[word2_start]\n",
    "            stops2 = stops_by_start[word2_start]\n",
    "\n",
    "            # Concatenate the first word with each of the second set of words\n",
    "            word1_copies = []  # Make n copies of word1 so as to pair with n words2\n",
    "            [word1_copies.extend([word1]) for x in range(len(words2))]\n",
    "            words2_list = [[x] for x in words2]\n",
    "            new_words.append(concatenate_lists(word1_copies, words2_list))\n",
    "            new_stops.append(stops2)\n",
    "\n",
    "    new_words = flatten_to_sublists_of_strings(new_words)\n",
    "    new_stops = flatten_list(new_stops)\n",
    "        \n",
    "    return new_words, new_stops\n",
    "\n",
    "\n",
    "def words_stop_to_start(words_by_start, stops_by_start, unique_starts, max_stop, max_count, \n",
    "                        consonants=None, do_swap_consonants=False):\n",
    "    '''\n",
    "    Create a list of text strings from sequences of words using the words' start and stop indices.\n",
    "\n",
    "    Output: output_lines\n",
    "\n",
    "    >>> # input_sentence = 'Uh, which is it, self-conscious or without agency?'\n",
    "    >>> # words = input_sentence.split('-')  #words = [re.sub(r'[^\\'A-Za-z\\-]', '', x).lower() for x in words]\n",
    "    >>> # phonemes, consonants, stresses, nsyllables = words_to_sounds(words, phoneme_list, consonant_list)\n",
    "    >>> # words_starts_stops = phonemes_to_words(phonemes, all_words, all_pronunciations, all_consonants, \n",
    "        #                                        consonant_list, just_consonants, max_phonemes_per_word, \n",
    "        #                                        ignore_words)\n",
    "    >>> # words_starts_stops = flatten_to_sublists_of_strings(words_starts_stops) \n",
    "    >>> # words_by_start, stops_by_start, unique_starts, unique_stops, max_start, max_stop = organize_words_by_start(words_starts_stops)\n",
    "    >>> words_by_start = [['a', 'uh', 'uhh'],['which', 'witch', \"which's\", \"witch's\"],['itch'],[],['is'],[],\n",
    "      ['it', \"it's\", 'its', 'itself'],[],['self'],['eh', 'elf'],[],['conscious'],\n",
    "      ['ah', 'ahh', 'awe'],[],['uh', 'uhh', 'us'],['saw', 'soar', 'sore'],\n",
    "      ['aw', 'oar', 'or', 'ore'],[],['withe', 'without'],[],[],['out'],[],\n",
    "      ['age', 'agency'],[],['uh', 'uhh']]\n",
    "    >>> stops_by_start = [[0, 0, 0],[3, 3, 5, 5],[3],[],[5],[],[7, 8, 8, 10],[],[10],[9, 10],[],[15],[12, 12, 12],[],[14, 14, 15],[16, 17, 17],\n",
    "                          [16, 17, 17, 17],[],[20, 22],[],[],[22],[],[24, 27],[],[25, 25]]\n",
    "    >>> unique_starts = [0, 1, 2, 4, 6, 8, 9, 11, 12, 14, 15, 16, 18, 21, 23, 25]\n",
    "    >>> max_stop = 27\n",
    "    >>> max_count = 26\n",
    "    >>> consonants = None\n",
    "    >>> do_swap_consonants = False\n",
    "    >>> words_stop_to_start(words_by_start, stops_by_start, unique_starts, max_stop, max_count, \n",
    "                            consonants, do_swap_consonants)\n",
    "                            \n",
    "    [\"a which's itself conscious oar without agency\",\n",
    "     \"a which's itself conscious or without agency\",\n",
    "     \"a which's itself conscious ore without agency\",\n",
    "     \"a witch's itself conscious oar without agency\",\n",
    "     \"a witch's itself conscious or without agency\",\n",
    "     \"a witch's itself conscious ore without agency\",\n",
    "     \"uh which's itself conscious oar without agency\",\n",
    "     \"uh which's itself conscious or without agency\",\n",
    "     \"uh which's itself conscious ore without agency\",\n",
    "     \"uh witch's itself conscious oar without agency\",\n",
    "     \"uh witch's itself conscious or without agency\",\n",
    "     \"uh witch's itself conscious ore without agency\",\n",
    "     \"uhh which's itself conscious oar without agency\",\n",
    "     \"uhh which's itself conscious or without agency\",\n",
    "     \"uhh which's itself conscious ore without agency\",\n",
    "     \"uhh witch's itself conscious oar without agency\",\n",
    "     \"uhh witch's itself conscious or without agency\",\n",
    "     \"uhh witch's itself conscious ore without agency\",\n",
    "     'a which is itself conscious oar without agency',\n",
    "     'a which is itself conscious or without agency',\n",
    "     'a which is itself conscious ore without agency',\n",
    "     'a witch is itself conscious oar without agency',\n",
    "               'a witch is itself conscious or without agency',\n",
    "     'a witch is itself conscious ore without agency',\n",
    "     \"a which's it self conscious oar without agency\",\n",
    "     \"a which's it self conscious or without agency\",\n",
    "     \"a which's it self conscious ore without agency\",\n",
    "     \"a which's it's elf conscious oar without agency\",\n",
    "     \"a which's it's elf conscious or without agency\",\n",
    "     \"a which's it's elf conscious ore without agency\",\n",
    "     \"a which's its elf conscious oar without agency\",\n",
    "     \"a which's its elf conscious or without agency\",\n",
    "     \"a which's its elf conscious ore without agency\",\n",
    "     \"a which's itself conscious oar withe out agency\",\n",
    "     \"a which's itself conscious or withe out agency\",\n",
    "     \"a which's itself conscious ore withe out agency\",\n",
    "     \"a witch's it self conscious oar without agency\",\n",
    "     \"a witch's it self conscious or without agency\",\n",
    "     \"a witch's it self conscious ore without agency\",\n",
    "     \"a witch's it's elf conscious oar without agency\",\n",
    "     \"a witch's it's elf conscious or without agency\",\n",
    "     \"a witch's it's elf conscious ore without agency\",\n",
    "     \"a witch's its elf conscious oar without agency\",\n",
    "     \"a witch's its elf conscious or without agency\",\n",
    "     \"a witch's its elf conscious ore without agency\",\n",
    "     \"a witch's itself conscious oar withe out agency\",\n",
    "     \"a witch's itself conscious or withe out agency\",\n",
    "     \"a witch's itself conscious ore withe out agency\",\n",
    "     'uh which is itself conscious oar without agency',\n",
    "     'uh which is itself conscious or without agency',\n",
    "     'uh which is itself conscious ore without agency',\n",
    "     'uh witch is itself conscious oar without agency',\n",
    "     'uh witch is itself conscious or without agency',\n",
    "     'uh witch is itself conscious ore without agency',\n",
    "     \"uh which's it self conscious oar without agency\",\n",
    "     \"uh which's it self conscious or without agency\",\n",
    "     \"uh which's it self conscious ore without agency\",\n",
    "     \"uh which's it's elf conscious oar without agency\",\n",
    "     \"uh which's it's elf conscious or without agency\",\n",
    "     \"uh which's it's elf conscious ore without agency\",\n",
    "     \"uh which's its elf conscious oar without agency\",\n",
    "     \"uh which's its elf conscious or without agency\",\n",
    "     \"uh which's its elf conscious ore without agency\",\n",
    "     \"uh which's itself conscious oar withe out agency\",\n",
    "     \"uh which's itself conscious or withe out agency\",\n",
    "     \"uh which's itself conscious ore withe out agency\",\n",
    "     \"uh witch's it self conscious oar without agency\",\n",
    "     \"uh witch's it self conscious or without agency\",\n",
    "     \"uh witch's it self conscious ore without agency\",\n",
    "     \"uh witch's it's elf conscious oar without agency\",\n",
    "     \"uh witch's it's elf conscious or without agency\",\n",
    "     \"uh witch's it's elf conscious ore without agency\",\n",
    "     \"uh witch's its elf conscious oar without agency\",\n",
    "     \"uh witch's its elf conscious or without agency\",\n",
    "     \"uh witch's its elf conscious ore without agency\",\n",
    "     \"uh witch's itself conscious oar withe out agency\",\n",
    "     \"uh witch's itself conscious or withe out agency\",\n",
    "     \"uh witch's itself conscious ore withe out agency\",\n",
    "     'uhh which is itself conscious oar without agency',\n",
    "     'uhh which is itself conscious or without agency',\n",
    "     'uhh which is itself conscious ore without agency',\n",
    "     'uhh witch is itself conscious oar without agency',\n",
    "     'uhh witch is itself conscious or without agency',\n",
    "     'uhh witch is itself conscious ore without agency',\n",
    "     \"uhh which's it self conscious oar without agency\",\n",
    "     \"uhh which's it self conscious or without agency\",\n",
    "     \"uhh which's it self conscious ore without agency\",\n",
    "     \"uhh which's it's elf conscious oar without agency\",\n",
    "     \"uhh which's it's elf conscious or without agency\",\n",
    "     \"uhh which's it's elf conscious ore without agency\",\n",
    "     \"uhh which's its elf conscious oar without agency\",\n",
    "     \"uhh which's its elf conscious or without agency\",\n",
    "     \"uhh which's its elf conscious ore without agency\",\n",
    "     \"uhh which's itself conscious oar withe out agency\",\n",
    "     \"uhh which's itself conscious or withe out agency\",\n",
    "     \"uhh which's itself conscious ore withe out agency\",\n",
    "     \"uhh witch's it self conscious oar without agency\",\n",
    "     \"uhh witch's it self conscious or without agency\",\n",
    "     \"uhh witch's it self conscious ore without agency\",\n",
    "     \"uhh witch's it's elf conscious oar without agency\",\n",
    "     \"uhh witch's it's elf conscious or without agency\",\n",
    "     \"uhh witch's it's elf conscious ore without agency\",\n",
    "     \"uhh witch's its elf conscious oar without agency\",\n",
    "     \"uhh witch's its elf conscious or without agency\",\n",
    "     \"uhh witch's its elf conscious ore without agency\",\n",
    "     \"uhh witch's itself conscious oar withe out agency\",\n",
    "     \"uhh witch's itself conscious or withe out agency\",\n",
    "     \"uhh witch's itself conscious ore withe out agency\",\n",
    "     'a which is it self conscious oar without agency',\n",
    "     'a which is it self conscious or without agency',\n",
    "     'a which is it self conscious ore without agency',\n",
    "     \"a which is it's elf conscious oar without agency\",\n",
    "     \"a which is it's elf conscious or without agency\",\n",
    "     \"a which is it's elf conscious ore without agency\",\n",
    "     'a which is its elf conscious oar without agency',\n",
    "     'a which is its elf conscious or without agency',\n",
    "     'a which is its elf conscious ore without agency',\n",
    "     'a which is itself conscious oar withe out agency',\n",
    "     'a which is itself conscious or withe out agency',\n",
    "     'a which is itself conscious ore withe out agency',\n",
    "     'a witch is it self conscious oar without agency',\n",
    "     'a witch is it self conscious or without agency',\n",
    "     'a witch is it self conscious ore without agency',\n",
    "     \"a witch is it's elf conscious oar without agency\",\n",
    "     \"a witch is it's elf conscious or without agency\",\n",
    "     \"a witch is it's elf conscious ore without agency\",\n",
    "     'a witch is its elf conscious oar without agency',\n",
    "     'a witch is its elf conscious or without agency',\n",
    "     'a witch is its elf conscious ore without agency',\n",
    "     'a witch is itself conscious oar withe out agency',\n",
    "     'a witch is itself conscious or withe out agency',\n",
    "     'a witch is itself conscious ore withe out agency',\n",
    "     \"a which's it self conscious oar withe out agency\",\n",
    "     \"a which's it self conscious or withe out agency\",\n",
    "     \"a which's it self conscious ore withe out agency\",\n",
    "     \"a which's it's elf conscious oar withe out agency\",\n",
    "     \"a which's it's elf conscious or withe out agency\",\n",
    "     \"a which's it's elf conscious ore withe out agency\",\n",
    "     \"a which's its elf conscious oar withe out agency\",\n",
    "     \"a which's its elf conscious or withe out agency\",\n",
    "     \"a which's its elf conscious ore withe out agency\",\n",
    "     \"a witch's it self conscious oar withe out agency\",\n",
    "     \"a witch's it self conscious or withe out agency\",\n",
    "     \"a witch's it self conscious ore withe out agency\",\n",
    "     \"a witch's it's elf conscious oar withe out agency\",\n",
    "     \"a witch's it's elf conscious or withe out agency\",\n",
    "     \"a witch's it's elf conscious ore withe out agency\",\n",
    "     \"a witch's its elf conscious oar withe out agency\",\n",
    "     \"a witch's its elf conscious or withe out agency\",\n",
    "     \"a witch's its elf conscious ore withe out agency\",\n",
    "     'uh which is it self conscious oar without agency',\n",
    "     'uh which is it self conscious or without agency',\n",
    "     'uh which is it self conscious ore without agency',\n",
    "     \"uh which is it's elf conscious oar without agency\",\n",
    "     \"uh which is it's elf conscious or without agency\",\n",
    "     \"uh which is it's elf conscious ore without agency\",\n",
    "     'uh which is its elf conscious oar without agency',\n",
    "     'uh which is its elf conscious or without agency',\n",
    "     'uh which is its elf conscious ore without agency',\n",
    "     'uh which is itself conscious oar withe out agency',\n",
    "     'uh which is itself conscious or withe out agency',\n",
    "     'uh which is itself conscious ore withe out agency',\n",
    "     'uh witch is it self conscious oar without agency',\n",
    "     'uh witch is it self conscious or without agency',\n",
    "     'uh witch is it self conscious ore without agency',\n",
    "     \"uh witch is it's elf conscious oar without agency\",\n",
    "     \"uh witch is it's elf conscious or without agency\",\n",
    "     \"uh witch is it's elf conscious ore without agency\",\n",
    "     'uh witch is its elf conscious oar without agency',\n",
    "     'uh witch is its elf conscious or without agency',\n",
    "     'uh witch is its elf conscious ore without agency',\n",
    "     'uh witch is itself conscious oar withe out agency',\n",
    "     'uh witch is itself conscious or withe out agency',\n",
    "     'uh witch is itself conscious ore withe out agency',\n",
    "     \"uh which's it self conscious oar withe out agency\",\n",
    "     \"uh which's it self conscious or withe out agency\",\n",
    "     \"uh which's it self conscious ore withe out agency\",\n",
    "     \"uh which's it's elf conscious oar withe out agency\",\n",
    "     \"uh which's it's elf conscious or withe out agency\",\n",
    "     \"uh which's it's elf conscious ore withe out agency\",\n",
    "     \"uh which's its elf conscious oar withe out agency\",\n",
    "     \"uh which's its elf conscious or withe out agency\",\n",
    "     \"uh which's its elf conscious ore withe out agency\",\n",
    "     \"uh witch's it self conscious oar withe out agency\",\n",
    "     \"uh witch's it self conscious or withe out agency\",\n",
    "     \"uh witch's it self conscious ore withe out agency\",\n",
    "     \"uh witch's it's elf conscious oar withe out agency\",\n",
    "     \"uh witch's it's elf conscious or withe out agency\",\n",
    "     \"uh witch's it's elf conscious ore withe out agency\",\n",
    "     \"uh witch's its elf conscious oar withe out agency\",\n",
    "     \"uh witch's its elf conscious or withe out agency\",\n",
    "     \"uh witch's its elf conscious ore withe out agency\",\n",
    "     'uhh which is it self conscious oar without agency',\n",
    "     'uhh which is it self conscious or without agency',\n",
    "     'uhh which is it self conscious ore without agency',\n",
    "     \"uhh which is it's elf conscious oar without agency\",\n",
    "     \"uhh which is it's elf conscious or without agency\",\n",
    "     \"uhh which is it's elf conscious ore without agency\",\n",
    "     'uhh which is its elf conscious oar without agency',\n",
    "     'uhh which is its elf conscious or without agency',\n",
    "     'uhh which is its elf conscious ore without agency',\n",
    "     'uhh which is itself conscious oar withe out agency',\n",
    "     'uhh which is itself conscious or withe out agency',\n",
    "     'uhh which is itself conscious ore withe out agency',\n",
    "     'uhh witch is it self conscious oar without agency',\n",
    "     'uhh witch is it self conscious or without agency',\n",
    "     'uhh witch is it self conscious ore without agency',\n",
    "     \"uhh witch is it's elf conscious oar without agency\",\n",
    "     \"uhh witch is it's elf conscious or without agency\",\n",
    "     \"uhh witch is it's elf conscious ore without agency\",\n",
    "     'uhh witch is its elf conscious oar without agency',\n",
    "     'uhh witch is its elf conscious or without agency',\n",
    "     'uhh witch is its elf conscious ore without agency',\n",
    "     'uhh witch is itself conscious oar withe out agency',\n",
    "     'uhh witch is itself conscious or withe out agency',\n",
    "     'uhh witch is itself conscious ore withe out agency',\n",
    "     \"uhh which's it self conscious oar withe out agency\",\n",
    "     \"uhh which's it self conscious or withe out agency\",\n",
    "     \"uhh which's it self conscious ore withe out agency\",\n",
    "     \"uhh which's it's elf conscious oar withe out agency\",\n",
    "     \"uhh which's it's elf conscious or withe out agency\",\n",
    "     \"uhh which's it's elf conscious ore withe out agency\",\n",
    "     \"uhh which's its elf conscious oar withe out agency\",\n",
    "     \"uhh which's its elf conscious or withe out agency\",\n",
    "     \"uhh which's its elf conscious ore withe out agency\",\n",
    "     \"uhh witch's it self conscious oar withe out agency\",\n",
    "     \"uhh witch's it self conscious or withe out agency\",\n",
    "     \"uhh witch's it self conscious ore withe out agency\",\n",
    "     \"uhh witch's it's elf conscious oar withe out agency\",\n",
    "     \"uhh witch's it's elf conscious or withe out agency\",\n",
    "     \"uhh witch's it's elf conscious ore withe out agency\",\n",
    "     \"uhh witch's its elf conscious oar withe out agency\",\n",
    "     \"uhh witch's its elf conscious or withe out agency\",\n",
    "     \"uhh witch's its elf conscious ore withe out agency\",\n",
    "     'a which is it self conscious oar withe out agency',\n",
    "     'a which is it self conscious or withe out agency',\n",
    "     'a which is it self conscious ore withe out agency',\n",
    "     \"a which is it's elf conscious oar withe out agency\",\n",
    "     \"a which is it's elf conscious or withe out agency\",\n",
    "     \"a which is it's elf conscious ore withe out agency\",\n",
    "     'a which is its elf conscious oar withe out agency',\n",
    "     'a which is its elf conscious or withe out agency',\n",
    "     'a which is its elf conscious ore withe out agency',\n",
    "     'a witch is it self conscious oar withe out agency',\n",
    "     'a witch is it self conscious or withe out agency',\n",
    "     'a witch is it self conscious ore withe out agency',\n",
    "     \"a witch is it's elf conscious oar withe out agency\",\n",
    "     \"a witch is it's elf conscious or withe out agency\",\n",
    "     \"a witch is it's elf conscious ore withe out agency\",\n",
    "     'a witch is its elf conscious oar withe out agency',\n",
    "     'a witch is its elf conscious or withe out agency',\n",
    "     'a witch is its elf conscious ore withe out agency',\n",
    "     'uh which is it self conscious oar withe out agency',\n",
    "     'uh which is it self conscious or withe out agency',\n",
    "     'uh which is it self conscious ore withe out agency',\n",
    "     \"uh which is it's elf conscious oar withe out agency\",\n",
    "     \"uh which is it's elf conscious or withe out agency\",\n",
    "     \"uh which is it's elf conscious ore withe out agency\",\n",
    "     'uh which is its elf conscious oar withe out agency',\n",
    "     'uh which is its elf conscious or withe out agency',\n",
    "     'uh which is its elf conscious ore withe out agency',\n",
    "     'uh witch is it self conscious oar withe out agency',\n",
    "     'uh witch is it self conscious or withe out agency',\n",
    "     'uh witch is it self conscious ore withe out agency',\n",
    "     \"uh witch is it's elf conscious oar withe out agency\",\n",
    "     \"uh witch is it's elf conscious or withe out agency\",\n",
    "     \"uh witch is it's elf conscious ore withe out agency\",\n",
    "     'uh witch is its elf conscious oar withe out agency',\n",
    "     'uh witch is its elf conscious or withe out agency',\n",
    "     'uh witch is its elf conscious ore withe out agency',\n",
    "     'uhh which is it self conscious oar withe out agency',\n",
    "     'uhh which is it self conscious or withe out agency',\n",
    "     'uhh which is it self conscious ore withe out agency',\n",
    "     \"uhh which is it's elf conscious oar withe out agency\",\n",
    "     \"uhh which is it's elf conscious or withe out agency\",\n",
    "     \"uhh which is it's elf conscious ore withe out agency\",\n",
    "     'uhh which is its elf conscious oar withe out agency',\n",
    "     'uhh which is its elf conscious or withe out agency',\n",
    "     'uhh which is its elf conscious ore withe out agency',\n",
    "     'uhh witch is it self conscious oar withe out agency',\n",
    "     'uhh witch is it self conscious or withe out agency',\n",
    "     'uhh witch is it self conscious ore withe out agency',\n",
    "     \"uhh witch is it's elf conscious oar withe out agency\",\n",
    "     \"uhh witch is it's elf conscious or withe out agency\",\n",
    "     \"uhh witch is it's elf conscious ore withe out agency\",\n",
    "     'uhh witch is its elf conscious oar withe out agency',\n",
    "     'uhh witch is its elf conscious or withe out agency',\n",
    "     'uhh witch is its elf conscious ore withe out agency']\n",
    "\n",
    "     '''    \n",
    "    \n",
    "    # Initialize a list of output text strings \n",
    "    output_lines = []\n",
    "\n",
    "    # Initialize loop to build a text string from the first words to the final words in a word list\n",
    "    max_words = []\n",
    "    max_stops = []\n",
    "    prev_words = words_by_start[0]\n",
    "    prev_stops = stops_by_start[0]\n",
    "    count = 1\n",
    "    run = True\n",
    "    while(run):\n",
    "        count += 1\n",
    "\n",
    "        # Concatenate new words to previous words\n",
    "        new_words, new_stops = concatenate_word_pairs(prev_words, prev_stops, \n",
    "                                                      words_by_start, stops_by_start, unique_starts)\n",
    "        \n",
    "        # Store the words that have reached the maximum stop\n",
    "        # and prepare to concatenate more words in the next loop\n",
    "        prev_words = []\n",
    "        prev_stops = []\n",
    "        for i,x in enumerate(new_stops):\n",
    "            if x == max_stop:\n",
    "                max_stops.append(x)\n",
    "                max_words.append(new_words[i])\n",
    "            else:\n",
    "                prev_stops.append(x)\n",
    "                prev_words.append(new_words[i])\n",
    "               \n",
    "        # Halt when all stops equal max_stop or until we loop max_count times\n",
    "        if all([x == max_stop for x in new_stops]) or count == max_count:\n",
    "            run = False\n",
    "\n",
    "    # Convert each word list to a text string\n",
    "    [output_lines.append(' '.join(x)) for x in max_words]\n",
    "\n",
    "    return output_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfeb3bd",
   "metadata": {},
   "source": [
    "## Homophone generator (same sounds, different words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ee03382",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_homophones(phonemes, max_count, max_phonemes_per_word, just_consonants=False, \n",
    "                        do_permute_consonants=False, ignore_words=None, verbose=False):\n",
    "    '''\n",
    "    Generate homophone words or sentences (same sounds, different words) from a sequence of phonemes.\n",
    "    \n",
    "    If just_consonants is set to True, then generate words or sentences from a sequence of consonants \n",
    "    (same consonants and consonant neighbors, different vowels).\n",
    "\n",
    "    >>> input_sentence = 'Uh, which is it, self-conscious or without agency?'\n",
    "    >>> words = input_sentence.split('-')  #words = [re.sub(r'[^\\'A-Za-z\\-]', '', x).lower() for x in words]\n",
    "    >>> phonemes, consonants, stresses, nsyllables = words_to_sounds(words, phoneme_list, consonant_list)\n",
    "    >>> phonemes = separate_consonants(phonemes)\n",
    "    >>> max_count = 26\n",
    "    >>> max_phonemes_per_word = 25\n",
    "    >>> just_consonants = False\n",
    "    >>> do_permute_consonants = False\n",
    "    >>> ignore_words = None\n",
    "    >>> verbose = False\n",
    "    generate_homophones(phonemes, max_count, max_phonemes_per_word, just_consonants, do_permute_consonants, \n",
    "                        ignore_words, verbose)\n",
    "                        \n",
    "    [\"a which's itself conscious oar without agency\",\n",
    "     ...\n",
    "     'a which is itself conscious or without agency',\n",
    "     ...\n",
    "     \"uhh which is itself conscious oar without age 'n sci\",\n",
    "     ...]\n",
    " \n",
    "    >>> just_consonants = True\n",
    "    generate_homophones(phonemes, max_count, max_phonemes_per_word, just_consonants, do_permute_consonants,\n",
    "                        ignore_words, verbose)\n",
    "    ['languages continue to evolve',\n",
    "     'languages continue too evolve',\n",
    "     'languages continue two evolve']\n",
    "    '''\n",
    "    \n",
    "    # Permute consonants (different sequence of same consonants, different vowels)\n",
    "    if do_permute_consonants and just_consonants:\n",
    "        consonants = [x for x in phonemes if x in consonant_list]\n",
    "        consonant_permutations = [x for x in permutations(consonants)]\n",
    "\n",
    "        # Loop through every permutation of consonants\n",
    "        words_starts_stops = []\n",
    "        for consonant_permutation in consonant_permutations:\n",
    "            phoneme_permutation = []\n",
    "            count = 0\n",
    "            for phoneme in phonemes:\n",
    "                if phoneme in consonant_list:\n",
    "                    phoneme_permutation.append(consonant_permutation[count])\n",
    "                    count += 1\n",
    "                else:\n",
    "                    phoneme_permutation.append(phoneme)\n",
    "\n",
    "            words_starts_stops_permutation = phonemes_to_words(phoneme_permutation, all_words, all_pronunciations, \n",
    "                                                               all_consonants, consonant_list, True, \n",
    "                                                               max_phonemes_per_word, ignore_words)\n",
    "            words_starts_stops.extend(words_starts_stops_permutation)\n",
    " \n",
    "    else:\n",
    "        words_starts_stops = phonemes_to_words(phonemes, all_words, all_pronunciations, all_consonants, \n",
    "                                               consonant_list, just_consonants, max_phonemes_per_word, \n",
    "                                               ignore_words)\n",
    "\n",
    "    if words_starts_stops:\n",
    "        #consonants1 = separate_consonants(consonants)\n",
    "        #phonemes2, consonants2, stresses2, syllables2 = words_to_sounds(new_words[istop], \n",
    "        #consonants2 = separate_consonants(consonants2)\n",
    "        #if len(consonants1) != len(consonants2):\n",
    "        #    go = False\n",
    "\n",
    "        if verbose:\n",
    "            print('Words: {0}'.format(', '.join([x[0] for x in words_starts_stops])), end='\\n')\n",
    "        words_starts_stops = flatten_to_sublists_of_strings(words_starts_stops) \n",
    "        words_by_start, stops, unique_starts, unique_stops, max_start, max_stop = organize_words_by_start(words_starts_stops)\n",
    "        #print('Words sorted by start index:  {0}'.format(words_by_start), end='\\n')\n",
    "        homophones = words_stop_to_start(words_by_start, stops, unique_starts, max_stop, max_count, None, False)\n",
    "    else:\n",
    "        homophones = None\n",
    "    \n",
    "    return homophones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697a0c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: away, way, we, wee, weigh, whew, whey, whoa, why, woe, woo, wow, wowie, watch, which, witch, watches, which's, witches, witch's, away, way, we, wee, weigh, whew, whey, whoa, why, woe, woo, wow, wowie, watch, which, witch, watches, which's, witches, witch's, chai, chew, chewy, chia, chow, ciao, each, etch, itch, itchy, ouch, achoa's, cheese, cheesy, che's, chews, choose, choosy, chose, chows, etches, h's, itches, occhoa's, chai, chew, chewy, chia, chow, ciao, each, etch, itch, itchy, ouch, achoa's, cheese, cheesy, che's, chews, choose, choosy, chose, chows, etches, h's, itches, occhoa's, ais, as, a's, ayes, ease, easy, e's, eye's, eyes, eyes', i's, is, oh's, ohs, oohs, ooze, o's, owes, oz, zoo, zeta, ais, as, a's, ayes, ease, easy, e's, eye's, eyes, eyes', i's, is, oh's, ohs, oohs, ooze, o's, owes, oz, zoo, zeta, at, ate, auto, eat, eight, eighty, iota, it, oat, ought, out, outta, ta, tai, tea, tee, ti, tie, to, toe, too, tow, toy, two, eats, eight's, eights, it's, its, oats, out's, outs, outsell, itself, at, ate, auto, eat, eight, eighty, iota, it, oat, ought, out, outta, ta, tai, tea, tee, ti, tie, to, toe, too, tow, toy, two, eats, eight's, eights, it's, its, oats, out's, outs, outsell, itself, ac, ace, ass, assay, essay, ice, icy, psi, 's, saw, say, sci, sea, see, sew, sigh, so, solely, sow, soy, sue, us, assail, cell, icily, sail, sale, sally, seal, sell, sill, silly, silo, soil, sol, sole, solo, soul, sully, self, sulfa, sylph, ail, aisle, ale, aliyah, all, allay, alley, allow, alloy, ally, aloe, eel, ell, i'll, ill, isle, la, law, lay, lea, lee, lei, lie, lieu, lo, loo, lough, low, luau, lye, oil, oily, ol', ole, oleo, owl, alpha, elf, ail, aisle, ale, aliyah, all, allay, alley, allow, alloy, ally, aloe, eel, ell, i'll, ill, isle, la, law, lay, lea, lee, lei, lie, lieu, lo, loo, lough, low, luau, lye, oil, oily, ol', ole, oleo, owl, alpha, elf, fay, fee, fey, foe, foo, if, iffy, off, phi, phooey, ache, achy, aka, ca, cat-2, caw, cay, chi, co, coo, coup, cow, coy, echo, eco, eke, 'kay, kayo, key, oak, och, ok, okay, outtake, quay, akin, can, cane, canny, canoe, cayenne, coin, con, cone, coon, econ, icon, kana, keen, ken, keno, khan, kin, conscious, an, anew, annoy, any, en, ennui, eon, gnaw, gnu, in, inn, ion, knee, knew, know, 'n, nah, nay, ne, nee, new, nigh, no, now, nu, on, own, unknown, an, anew, annoy, any, en, ennui, eon, gnaw, gnu, in, inn, ion, knee, knew, know, 'n, nah, nay, ne, nee, new, nigh, no, now, nu, on, own, unknown, ash, ashy, issue, shah, shay, she, shew, shh, shoe, shoo, show, showy, shy, xi, ac, ace, ass, assay, essay, ice, icy, psi, 's, saw, say, sci, sea, see, sew, sigh, so, solely, sow, soy, sue, us, assayer, ceara, eyesore, sari, sear, seer, sere, sewer, sierra, sir, sire, soar, sore, sorrow, sorry, sour, sower, surrey, ac, ace, ass, assay, essay, ice, icy, psi, 's, saw, say, sci, sea, see, sew, sigh, so, solely, sow, soy, sue, us, assayer, ceara, eyesore, sari, sear, seer, sere, sewer, sierra, sir, sire, soar, sore, sorrow, sorry, sour, sower, surrey, aerie, aero, air, airy, are, area, aria, array, arrow, arroyo, aura, awry, ear, eerie, er, era, ere, err, heir, hour, ire, oar, or, ore, our, rah, raw, ray, re, rhea, rho, roe, roux, row, rue, rye, wry, airway, aerie, aero, air, airy, are, area, aria, array, arrow, arroyo, aura, awry, ear, eerie, er, era, ere, err, heir, hour, ire, oar, or, ore, our, rah, raw, ray, re, rhea, rho, roe, roux, row, rue, rye, wry, airway, away, way, we, wee, weigh, whew, whey, whoa, why, woe, woo, wow, wowie, withe, without, auth, oath, thaw, thigh, theta, thought, auth, oath, thaw, thigh, theta, thought, at, ate, auto, eat, eight, eighty, iota, it, oat, ought, out, outta, ta, tai, tea, tee, ti, tie, to, toe, too, tow, toy, two, outage, at, ate, auto, eat, eight, eighty, iota, it, oat, ought, out, outta, ta, tai, tea, tee, ti, tie, to, toe, too, tow, toy, two, outage, age, edge, edgy, gee, jaw, jay, joey, joy, adjoin, gene, genie, gin, jean, jenny, john, johnny, join, jun, agency, age, edge, edgy, gee, jaw, jay, joey, joy, adjoin, gene, genie, gin, jean, jenny, john, johnny, join, jun, agency, an, anew, annoy, any, en, ennui, eon, gnaw, gnu, in, inn, ion, knee, knew, know, 'n, nah, nay, ne, nee, new, nigh, no, now, nu, on, own, unknown, ensue, ounce, an, anew, annoy, any, en, ennui, eon, gnaw, gnu, in, inn, ion, knee, knew, know, 'n, nah, nay, ne, nee, new, nigh, no, now, nu, on, own, unknown, ensue, ounce, ac, ace, ass, assay, essay, ice, icy, psi, 's, saw, say, sci, sea, see, sew, sigh, so, solely, sow, soy, sue, us\n"
     ]
    }
   ],
   "source": [
    "    >>> just_consonants = True\n",
    "    generate_homophones(phonemes, max_count, max_phonemes_per_word, just_consonants, do_permute_consonants,ignore_words, verbose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d67c37d",
   "metadata": {},
   "source": [
    "## Process input/output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e01785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_lines(infile, outfile):\n",
    "    '''\n",
    "    Remove duplicate lines in a file.\n",
    "    '''\n",
    "    unique_lines = set(open(infile).readlines())\n",
    "    out = open(outfile, 'w').writelines(unique_lines)\n",
    "    \n",
    "\n",
    "def display_save_output(input_list, input_type, input_source, \n",
    "                        do_save_files=False, filename_base=None, verbose=False):\n",
    "    '''\n",
    "    Display outpute and/or write to text file.\n",
    "    '''\n",
    "\n",
    "    # Write output to a text file\n",
    "    if len(input_list) > 1:\n",
    "        if verbose:\n",
    "            print('')\n",
    "            print('==============================================================================================')\n",
    "            print('{0} {1}s for \"{2}\"'.format(len(input_list), input_type, input_source.strip()), end='\\n')\n",
    "            print('==============================================================================================')\n",
    "            #for line in flatten_list(input_list):\n",
    "            #   print('    {0}'.format(line), end='\\n')\n",
    "        if do_save_files:\n",
    "            outfile = filename_base + input_type.upper() + '.txt'\n",
    "            fwrite = open(outfile, \"w\")\n",
    "            fwrite.write('')\n",
    "            fwrite.close()\n",
    "            fwrite = open(outfile, \"a\")\n",
    "            for new_line in input_list:\n",
    "                fwrite.write(new_line + '\\n')\n",
    "            fwrite.close()\n",
    "            if verbose:\n",
    "                print('{0} written to {1}'.format(input_type.capitalize(), outfile), end='\\n')\n",
    "    else:\n",
    "        if verbose:\n",
    "            print('\\n0 {0} for \"{1}\"'.format(input_type, input_source.strip()), end='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5cbaed",
   "metadata": {},
   "source": [
    "## Run all code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6738eef3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "do_generate_homophones = True  # Generate homophones (same sounds, different words)\n",
    "do_generate_consonances = False  # Generate consonances (same consonants and consonant neighbors, different vowels)\n",
    "do_permute_consonants = False  # Permute consonants (different sequence of same consonants, different vowels)\n",
    "\n",
    "do_save_files = True\n",
    "verbose = True\n",
    "verbose2 = True\n",
    "\n",
    "# Parameters for each function\n",
    "do_split_up_consonants = True  # Split up consonant compounds (\"I scream\" => \"ice cream\")\n",
    "do_check_grammar = True\n",
    "do_check_grammar_again = False\n",
    "cap_and_punc = True\n",
    "ignore_inputs = []  # Don't use any of these words\n",
    "do_ignore_inputs = False  # Don't use any of the original words\n",
    "do_split_up_consonants = True  # Split up consonant compounds (\"I scream\" => \"ice cream\")?\n",
    "if do_split_up_consonants:\n",
    "    max_phonemes_per_word = 25\n",
    "else:\n",
    "    max_phonemes_per_word = 11      \n",
    "\n",
    "\n",
    "# Load each line of text\n",
    "input_file = \"input.txt\"\n",
    "fread = open(input_file, \"r\")\n",
    "lines = fread.readlines()\n",
    "filename_base = None        \n",
    "for line in lines:\n",
    "    words = line.split('-')  #words = [re.sub(r'[^\\'A-Za-z\\-]', '', x).lower() for x in words]\n",
    "    nwords = len(''.join(words))\n",
    "\n",
    "    # Convert words to phonemes\n",
    "    phonemes, consonants, stresses, nsyllables = words_to_sounds(words, phoneme_list, consonant_list)\n",
    "\n",
    "    # Split up consonant compounds (\"I scream\" => \"ice cream\")\n",
    "    if do_split_up_consonants:\n",
    "        phonemes = separate_consonants(phonemes)\n",
    "\n",
    "    # Set parameters\n",
    "    if do_ignore_inputs:\n",
    "        ignore_inputs = words\n",
    "    if do_save_files:\n",
    "        filename_base = 'output/' + '_'.join(words)\n",
    "    \n",
    "    print(\"\\nGenerate linguamorphs for each line of {0}:\".format(input_file))\n",
    "\n",
    "    # Homophones\n",
    "    if do_generate_homophones:\n",
    "        homophones = generate_homophones(phonemes, nwords, nsyllables, max_phonemes_per_word, False, False, ignore_inputs, verbose2)\n",
    "        homophones = check_grammar_twice(homophones, grammar_tool, grammar_tool2, cap_and_punc, do_check_grammar_again, verbose2)\n",
    "        display_save_output(homophones, 'homophones', line, do_save_files, filename_base, verbose)\n",
    "\n",
    "    # Consonances\n",
    "    if do_generate_consonances:\n",
    "        consonances = generate_homophones(phonemes, nwords, nsyllables, max_phonemes_per_word, True, False, ignore_inputs, verbose2)\n",
    "        consonances = check_grammar_twice(consonances, grammar_tool, grammar_tool2, cap_and_punc, do_check_grammar_again, verbose2)\n",
    "        display_save_output(consonances, 'consonances', line, do_save_files, filename_base, verbose)\n",
    "\n",
    "    # Swap-consonances\n",
    "    if do_swap_consonances:\n",
    "        swap_consonances = generate_homophones(phonemes, nwords, nsyllables, max_phonemes_per_word, True, True, ignore_inputs, verbose2)\n",
    "        swap_consonances = check_grammar_twice(consonances, grammar_tool, grammar_tool2, cap_and_punc, do_check_grammar_again, verbose2)\n",
    "        display_save_output(swap_consonances, 'swap_consonances', line, do_save_files, filename_base, verbose)\n",
    "\n",
    "    print('\\nDone!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a10f60",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
