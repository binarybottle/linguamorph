{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed26fee5",
   "metadata": {},
   "source": [
    "## Load lines of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15356870",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"demo.txt\", \"r\")\n",
    "lines = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc51f1a6",
   "metadata": {},
   "source": [
    "## Phonemes and Carnegie Mellon Pronouncing Dictionary\n",
    "\n",
    "(See https://github.com/cmusphinx/cmudict/tree/4c6a365cea2c34340ffc218d5af7a38920fa7e37)\n",
    "\n",
    "From https://www.nltk.org/_modules/nltk/corpus/reader/cmudict.html:\n",
    "\n",
    "The Carnegie Mellon Pronouncing Dictionary [cmudict.0.6]\n",
    "Copyright 1998 Carnegie Mellon University\n",
    "\n",
    "File Format: Each line consists of an uppercased word, a counter\n",
    "(for alternative pronunciations), and a transcription.  Vowels are\n",
    "marked for stress (1=primary, 2=secondary, 0=no stress).  E.g.:\n",
    "NATURAL 1 N AE1 CH ER0 AH0 L\n",
    "\n",
    "The dictionary contains 127069 entries.  Of these, 119400 words are assigned\n",
    "a unique pronunciation, 6830 words have two pronunciations, and 839 words have\n",
    "three or more pronunciations.  Many of these are fast-speech variants.\n",
    "\n",
    "Phonemes: There are 39 phonemes, as shown below:\n",
    "\n",
    "    Phoneme Example Translation    Phoneme Example Translation\n",
    "    ------- ------- -----------    ------- ------- -----------\n",
    "    AA      odd     AA D           AE      at      AE T\n",
    "    AH      hut     HH AH T        AO      ought   AO T\n",
    "    AW      cow     K AW           AY      hide    HH AY D\n",
    "    B       be      B IY           CH      cheese  CH IY Z\n",
    "    D       dee     D IY           DH      thee    DH IY\n",
    "    EH      Ed      EH D           ER      hurt    HH ER T\n",
    "    EY      ate     EY T           F       fee     F IY\n",
    "    G       green   G R IY N       HH      he      HH IY\n",
    "    IH      it      IH T           IY      eat     IY T\n",
    "    JH      gee     JH IY          K       key     K IY\n",
    "    L       lee     L IY           M       me      M IY\n",
    "    N       knee    N IY           NG      ping    P IH NG\n",
    "    OW      oat     OW T           OY      toy     T OY\n",
    "    P       pee     P IY           R       read    R IY D\n",
    "    S       sea     S IY           SH      she     SH IY\n",
    "    T       tea     T IY           TH      theta   TH EY T AH\n",
    "    UH      hood    HH UH D        UW      two     T UW\n",
    "    V       vee     V IY           W       we      W IY\n",
    "    Y       yield   Y IY L D       Z       zee     Z IY\n",
    "    ZH      seizure S IY ZH ER\n",
    "    \n",
    "From https://www.pythonstudio.us/language-processing/a-pronouncing-dictionary.html:\n",
    "\n",
    "For each word, this lexicon provides a list of phonetic codes—distinct labels for each contrastive sound—known as phones. Observe that fire has two pronunciations (in U.S. English): the one-syllable F AY1 R, and the two-syllable F AY1 ER0. The symbols in the CMU Pronouncing Dictionary are from the Arpabet, described in more detail at http://en.wikipedia.org/wiki/Arpabet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f2608ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "entries = nltk.corpus.cmudict.entries()\n",
    "\n",
    "phoneme_list = ['AA','AH','AW','B','D','EH','EY','G','IH','JH','L','N','OW','P','S','T','UH','V','Y','ZH',\n",
    "                'AE','AO','AY','CH','DH','ER','F','HH','IY','K','M','NG','OY','R','SH','TH','UW','W','Z']\n",
    "phoneme_vowel_list = ['AA','AH','AW','EH','EY','IH','OW','UH','AE','AO','AY','ER','IY','OY','UW']\n",
    "phoneme_consonant_list = ['B','D','G','JH','L','N','P','S','T','V','Y','ZH','CH',\n",
    "                          'DH','F','HH','K','M','NG','R','SH','TH','W','Z']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6325a139",
   "metadata": {},
   "source": [
    "## Code for converting words to phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a12faa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2p_en import G2p\n",
    "g2p = G2p()\n",
    "\n",
    "# Attempt to convert phonemes to graphemes:\n",
    "# https://github.com/wassname/phoneme2grapheme/blob/master/main.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c03345",
   "metadata": {},
   "source": [
    "## Code for converting phonemes to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "434440a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_numbers(numbers):\n",
    "    unique = []\n",
    "    for number in numbers:\n",
    "        if number not in unique:\n",
    "            unique.append(number)\n",
    "    return unique\n",
    "\n",
    "def p2g(phoneme_list, istart=0): \n",
    "    '''\n",
    "    Generate a list of words from a list of phonemes,\n",
    "    by concatenating sequences of the phonemes \n",
    "    and searching in CMU's Pronunciation Dictionary.\n",
    "    '''\n",
    "    words_from_phonemes = []\n",
    "    for istop in range(istart + 1, len(phoneme_list) + 1):\n",
    "        phoneme_subset = phoneme_list[istart:istop]\n",
    "        #print(phoneme_subset)\n",
    "        for word, pron in entries:\n",
    "            if len(pron) == len(phoneme_subset):\n",
    "                match = 0\n",
    "                for index, p in enumerate(pron):\n",
    "                    if re.sub(r'\\d+', '', p) == re.sub(r'\\d+', '', phoneme_subset[index]):\n",
    "                        match += 1\n",
    "                if match == len(pron):\n",
    "                    words_from_phonemes.append([word, istart, istart + index])\n",
    "                    \n",
    "    unique_stops = get_unique_numbers([i2 for x,i1,i2 in words_from_phonemes])\n",
    "\n",
    "    return words_from_phonemes, unique_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b563a4",
   "metadata": {},
   "source": [
    "## Code for counting syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c01e57e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://datascience.stackexchange.com/questions/23376/how-to-get-the-number-of-syllables-in-a-word\n",
    "\n",
    "import re\n",
    "\n",
    "VOWEL_RUNS = re.compile(\"[aeiouy]+\", flags=re.I)\n",
    "EXCEPTIONS = re.compile(\n",
    "    # fixes trailing e issues:\n",
    "    # smite, scared\n",
    "    \"[^aeiou]e[sd]?$|\"\n",
    "    # fixes adverbs:\n",
    "    # nicely\n",
    "    + \"[^e]ely$\",\n",
    "    flags=re.I\n",
    ")\n",
    "ADDITIONAL = re.compile(\n",
    "    # fixes incorrect subtractions from exceptions:\n",
    "    # smile, scarred, raises, fated\n",
    "    \"[^aeioulr][lr]e[sd]?$|[csgz]es$|[td]ed$|\"\n",
    "    # fixes miscellaneous issues:\n",
    "    # flying, piano, video, prism, fire, evaluate\n",
    "    + \".y[aeiou]|ia(?!n$)|eo|ism$|[^aeiou]ire$|[^gq]ua\",\n",
    "    flags=re.I\n",
    ")\n",
    "\n",
    "def count_syllables(word):\n",
    "    vowel_runs = len(VOWEL_RUNS.findall(word))\n",
    "    exceptions = len(EXCEPTIONS.findall(word))\n",
    "    additional = len(ADDITIONAL.findall(word))\n",
    "    return max(1, vowel_runs - exceptions + additional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a7cbdb",
   "metadata": {},
   "source": [
    "## Find phonemes, stresses, and number of syllables per input line of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cd3c9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['L', 'AY', 'K', 'AH', 'D', 'AH', 'K', 'T', 'UW', 'W', 'AO', 'T', 'ER']]\n",
      "[['L', 'K', 'D', 'K', 'T', 'W', 'T']]\n",
      "[[0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]]\n",
      "[6]\n"
     ]
    }
   ],
   "source": [
    "phonemes_per_line = []\n",
    "stresses_per_line = []\n",
    "syllables_per_line = []\n",
    "consonants_per_line = []\n",
    "\n",
    "for line in lines:\n",
    "    if line.strip() != \"\":\n",
    "        words = line.split()\n",
    "        phonemes_for_line = []\n",
    "        stresses_for_line = []\n",
    "        syllables_for_line = 0\n",
    "        for word in words:\n",
    "            \n",
    "            # Extract phonemes per word (choose the first version of the phoneme)\n",
    "            #     :: multiple pronunciations: pronouncing.phones_for_word(word) \n",
    "            phonemes_and_stresses_for_word = g2p(word)\n",
    "                      \n",
    "            phonemes_for_word = [re.sub(r'\\d+', '', x) for x in phonemes_and_stresses_for_word]\n",
    "            stresses_blanks_for_word = [re.sub(r\"(?:[A-Z])\",'', x) for x in phonemes_and_stresses_for_word]\n",
    "            stresses_for_word = []\n",
    "            syllables_for_word = 0\n",
    "            for i,p in enumerate(phonemes_for_word):\n",
    "                if p in phoneme_list:\n",
    "                    if stresses_blanks_for_word[i] == '':\n",
    "                        stresses_for_word.append(0)\n",
    "                    elif stresses_blanks_for_word[i] == '0':\n",
    "                        stresses_for_word.append(0)\n",
    "                    elif stresses_blanks_for_word[i] == '1':\n",
    "                        stresses_for_word.append(1)\n",
    "                    elif stresses_blanks_for_word[i] == '2':\n",
    "                        stresses_for_word.append(2)                        \n",
    "            phonemes_for_word = [x for x in phonemes_for_word if x in phoneme_list]                  \n",
    "            phonemes_for_line += phonemes_for_word  \n",
    "            stresses_for_line += stresses_for_word\n",
    "            syllables_for_line += count_syllables(word)\n",
    "\n",
    "        phonemes_per_line.append(phonemes_for_line)\n",
    "        stresses_per_line.append(stresses_for_line)\n",
    "        syllables_per_line.append(syllables_for_line)\n",
    "        consonants_per_line.append([x for x in phonemes_for_line if x in phoneme_consonant_list]) \n",
    "\n",
    "print(phonemes_per_line)\n",
    "print(consonants_per_line)\n",
    "print(stresses_per_line)\n",
    "print(syllables_per_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abfe1db",
   "metadata": {},
   "source": [
    "## Find all words that sound like each segment of a phoneme list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "100a2dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['lai', 0, 1], ['lie', 0, 1], ['ly', 0, 1], ['lye', 0, 1], ['like', 0, 2], ['lyke', 0, 2], ['ca', 2, 3], ['cudd', 2, 4], ['a', 3, 3], ['uh', 3, 3], ['uhh', 3, 3], ['uhde', 3, 4], ['dah', 4, 5], ['de', 4, 5], ['du', 4, 5], ['duh', 4, 5], ['duc', 4, 6], ['duck', 4, 6], ['duk', 4, 6], ['ducked', 4, 7], ['duct', 4, 7], ['a', 5, 5], ['uh', 5, 5], ['uhh', 5, 5], ['ooh', 8, 8], ['oooh', 8, 8], ['ou', 8, 8], ['waugh', 9, 10], ['wat', 9, 11], ['water', 9, 12], ['ter', 11, 12], ['are', 12, 12], ['er', 12, 12], ['err', 12, 12], ['eure', 12, 12], ['or', 12, 12], ['ur', 12, 12]]]\n"
     ]
    }
   ],
   "source": [
    "new_words_per_line = []\n",
    "for phonemes_for_line in phonemes_per_line:   \n",
    "    new_words = []\n",
    "    istart = 0\n",
    "    unique_stops = [-1]\n",
    "    while istart < len(phonemes_for_line):\n",
    "        if len(unique_stops) == 0:\n",
    "            unique_stops = [istart + 1]\n",
    "        for istop in unique_stops:\n",
    "            istart = istop + 1\n",
    "            if istart < len(phonemes_for_line):\n",
    "                words_from_phonemes, unique_stops = p2g(phonemes_for_line, istart)\n",
    "                new_words += words_from_phonemes\n",
    "    new_words_per_line.append(new_words)\n",
    "    \n",
    "print(new_words_per_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3fe905",
   "metadata": {},
   "source": [
    "## Construct word sequences that sound like each line of input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b57a5455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['lai', 0, 1], ['lie', 0, 1], ['ly', 0, 1], ['lye', 0, 1], ['like', 0, 2], ['lyke', 0, 2], ['ca', 2, 3], ['cudd', 2, 4], ['a', 3, 3], ['uh', 3, 3], ['uhh', 3, 3], ['uhde', 3, 4], ['dah', 4, 5], ['de', 4, 5], ['du', 4, 5], ['duh', 4, 5], ['duc', 4, 6], ['duck', 4, 6], ['duk', 4, 6], ['ducked', 4, 7], ['duct', 4, 7], ['a', 5, 5], ['uh', 5, 5], ['uhh', 5, 5], ['ooh', 8, 8], ['oooh', 8, 8], ['ou', 8, 8], ['waugh', 9, 10], ['wat', 9, 11], ['water', 9, 12], ['ter', 11, 12], ['are', 12, 12], ['er', 12, 12], ['err', 12, 12], ['eure', 12, 12], ['or', 12, 12], ['ur', 12, 12]]\n",
      "['lai', 'lie', 'ly', 'lye', 'like', 'lyke'] [0, 0, 0, 0, 0, 0] [1, 1, 1, 1, 2, 2]\n",
      "lai\n",
      "lie\n",
      "ly\n",
      "lye\n",
      "like\n",
      "lyke\n"
     ]
    }
   ],
   "source": [
    "def find_words_with_istart_index(word_istart_istop_list, istart_index):\n",
    "    # store each word that begins at istart\n",
    "    istart_words = []\n",
    "    istart_istarts = []\n",
    "    istart_istops = []\n",
    "    for word, istart, istop in word_istart_istop_list:\n",
    "        if istart == istart_index:\n",
    "            istart_words.append(word)\n",
    "            istart_istarts.append(istart)\n",
    "            istart_istops.append(istop)\n",
    "    \n",
    "    return istart_words, istart_istarts, istart_istops\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "candidates_per_line = []\n",
    "for new_words_for_line in new_words_per_line:\n",
    "    new_words = []\n",
    "    istarts = []\n",
    "    istops = []\n",
    "    for new_word, istart, istop in new_words_for_line:\n",
    "        new_words.append(new_word)\n",
    "        istarts.append(istart)\n",
    "        istops.append(istop)        \n",
    "    unique_istarts = get_unique_numbers(istarts)\n",
    "    unique_istops = get_unique_numbers(istops)\n",
    "\n",
    "    #print(unique_istarts)\n",
    "    #print(unique_istops)\n",
    "    \n",
    "    new_line = []\n",
    "    running_start = 0\n",
    "    print(new_words_for_line)\n",
    "    \n",
    "#        find words that begin at that word's istop + 1\n",
    "#        advance to next word\n",
    "#            for each word that begins at that word's istop\n",
    "#                find words that begin at that word's istop + 1\n",
    "#\n",
    "#          add word if (1 + istop for word) in unique_istarts\n",
    "\n",
    "        \n",
    "#    unique_stops = [-1]\n",
    "#    while istart < len(phonemes_for_line):\n",
    "#        if len(unique_stops) == 0:\n",
    "#            unique_stops = [istart + 1]\n",
    "#        for istop in unique_stops:\n",
    "#            istart = istop + 1\n",
    "#            if istart < len(phonemes_for_line):\n",
    "#                words_from_phonemes, unique_stops = p2g(phonemes_for_line, istart)\n",
    "#                new_words += words_from_phonemes\n",
    "#    new_words_per_line.append(new_words)\n",
    "            \n",
    "    \n",
    "    istart_index = 0\n",
    "    running_start = 0\n",
    "    istart_words, istart_istarts, istart_istops = find_words_with_istart_index(new_words_for_line, istart_index)\n",
    "    print(istart_words, istart_istarts, istart_istops)\n",
    "    for i_istart_word, istart_word in enumerate(istart_words):\n",
    "        if running_start in unique_istarts:\n",
    "            if istart == running_start:\n",
    "                new_line.append(new_word)\n",
    "                running_start = istop + 1\n",
    "                #print(new_line)\n",
    "                #print(running_start)\n",
    "        else: \n",
    "            istart0 += 1\n",
    "            break\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for new_word, istart, istop in new_words_for_line:\n",
    "        #print(new_words_for_line[istart0::])\n",
    "        if running_start in unique_istarts:\n",
    "            if istart == running_start:\n",
    "                new_line.append(new_word)\n",
    "                running_start = istop + 1\n",
    "                #print(new_line)\n",
    "                #print(running_start)\n",
    "        else: \n",
    "            istart0 += 1\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d7e851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
